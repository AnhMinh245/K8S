# 1.1. Kubernetes LÃ  GÃ¬?

> Hiá»ƒu Kubernetes tá»« váº¥n Ä‘á» thá»±c táº¿ nÃ³ giáº£i quyáº¿t

---

## ğŸ¯ Má»¥c TiÃªu Há»c

Sau khi há»c xong pháº§n nÃ y, báº¡n sáº½:
- âœ… Hiá»ƒu **Táº I SAO** cáº§n Kubernetes
- âœ… Biáº¿t Kubernetes **GIáº¢I QUYáº¾T Váº¤N Äá»€ GÃŒ**
- âœ… Náº¯m Ä‘Æ°á»£c cÃ¡c tÃ­nh nÄƒng cá»‘t lÃµi
- âœ… So sÃ¡nh vá»›i cÃ¡ch deploy truyá»n thá»‘ng

---

## ğŸ¢ Váº¥n Äá» Trong Thá»±c Táº¿

### CÃ¢u Chuyá»‡n: Startup PhÃ¡t Triá»ƒn Nhanh

**Giai Ä‘oáº¡n 1: Khá»Ÿi Ä‘áº§u (10 users)**
```
Báº¡n cÃ³ 1 web app Ä‘Æ¡n giáº£n:
â”œâ”€â”€ Frontend (React)
â”œâ”€â”€ Backend (Node.js)
â””â”€â”€ Database (PostgreSQL)

Deploy: Cháº¡y trÃªn 1 server (VPS)
Cost: $20/thÃ¡ng
Problem: KhÃ´ng cÃ³!
```

**Giai Ä‘oáº¡n 2: TÄƒng trÆ°á»Ÿng (1,000 users)**
```
Server quÃ¡ táº£i!
â”œâ”€â”€ CPU: 90%
â”œâ”€â”€ Memory: 85%
â”œâ”€â”€ Response time: 5 giÃ¢y
â””â”€â”€ ÄÃªm nÃ o cÅ©ng bá»‹ crash

Solution: ThÃªm server!
```

**Giai Ä‘oáº¡n 3: Scale lÃªn (10,000 users)**
```
Báº¡n mua thÃªm 5 servers:
â”œâ”€â”€ Server 1: Frontend
â”œâ”€â”€ Server 2: Backend  
â”œâ”€â”€ Server 3: Backend (replica)
â”œâ”€â”€ Server 4: Database
â””â”€â”€ Server 5: Redis cache

Problems báº¯t Ä‘áº§u xuáº¥t hiá»‡n:
âŒ Server 2 cháº¿t â†’ 50% requests fail
âŒ Deploy code má»›i â†’ pháº£i SSH vÃ o tá»«ng server
âŒ Traffic spike â†’ khÃ´ng Ä‘á»§ server
âŒ 3AM server cháº¿t â†’ pháº£i thá»©c dáº­y restart
âŒ Scaling thá»§ cÃ´ng quÃ¡ cháº­m
âŒ Monitoring tá»«ng server riÃªng â†’ má»‡t má»i
```

**Giai Ä‘oáº¡n 4: Há»—n loáº¡n (100,000 users)**
```
20 servers, 50 containers:
âŒ Deploy máº¥t 2 giá»
âŒ KhÃ´ng biáº¿t container nÃ o cháº¡y á»Ÿ Ä‘Ã¢u
âŒ 1 server cháº¿t â†’ áº£nh hÆ°á»Ÿng nhiá»u services
âŒ KhÃ´ng biáº¿t server nÃ o Ä‘ang overload
âŒ Rollback code â†’ pháº£i lÃ m thá»§ cÃ´ng
âŒ Team máº¥t ngá»§ má»—i Ä‘Ãªm
```

### Váº¥n Äá» Cá»‘t LÃµi

Khi há»‡ thá»‘ng lá»›n lÃªn, báº¡n cáº§n:

1. **Tá»± Ä‘á»™ng hÃ³a** thay vÃ¬ thá»§ cÃ´ng
2. **Self-healing** khi cÃ³ lá»—i xáº£y ra
3. **Scaling** tá»± Ä‘á»™ng theo traffic
4. **Deploy** nhanh vÃ  an toÃ n
5. **Monitoring** táº­p trung
6. **Resource management** hiá»‡u quáº£

â†’ **ÄÃ‚Y LÃ€ LÃšC Cáº¦N KUBERNETES!**

---

## ğŸš€ Kubernetes LÃ  GÃ¬?

### Äá»‹nh NghÄ©a

**Kubernetes (K8s)** lÃ  má»™t ná»n táº£ng mÃ£ nguá»“n má»Ÿ Ä‘á»ƒ **tá»± Ä‘á»™ng hÃ³a viá»‡c triá»ƒn khai, má»Ÿ rá»™ng vÃ  quáº£n lÃ½ cÃ¡c á»©ng dá»¥ng container**.

### Giáº£i ThÃ­ch Báº±ng VÃ­ Dá»¥ Thá»±c Táº¿

**Kubernetes giá»‘ng nhÆ° má»™t "ngÆ°á»i quáº£n lÃ½ thÃ´ng minh" cho data center cá»§a báº¡n:**

```
ğŸ­ Data Center = NhÃ  mÃ¡y sáº£n xuáº¥t
ğŸ“¦ Container = CÃ´ng nhÃ¢n
ğŸ¯ Kubernetes = GiÃ¡m Ä‘á»‘c Ä‘iá»u hÃ nh

Kubernetes lÃ m gÃ¬:
âœ“ PhÃ¢n cÃ´ng viá»‡c cho workers (scheduling)
âœ“ Äáº£m báº£o Ä‘á»§ workers Ä‘ang lÃ m viá»‡c (replication)
âœ“ Thay tháº¿ worker bá»‹ á»‘m (self-healing)
âœ“ TÄƒng/giáº£m workers theo khá»‘i lÆ°á»£ng cÃ´ng viá»‡c (scaling)
âœ“ PhÃ¢n phá»‘i cÃ´ng viá»‡c Ä‘á»u (load balancing)
âœ“ Cáº­p nháº­t quy trÃ¬nh khÃ´ng giÃ¡n Ä‘oáº¡n (rolling updates)
```

---

## ğŸ’¡ Kubernetes Giáº£i Quyáº¿t NhÆ° Tháº¿ NÃ o?

### TrÆ°á»›c Kubernetes vs Vá»›i Kubernetes

**TRÆ¯á»šC (Manual):**
```bash
# Deploy code má»›i (pháº£i lÃ m trÃªn 20 servers!)
ssh server1 "docker pull myapp:v2 && docker restart myapp"
ssh server2 "docker pull myapp:v2 && docker restart myapp"
ssh server3 "docker pull myapp:v2 && docker restart myapp"
# ... 17 láº§n ná»¯a ğŸ˜«

# Server cháº¿t lÃºc 3 AM
â†’ Äiá»‡n thoáº¡i reo
â†’ Thá»©c dáº­y
â†’ SSH vÃ o
â†’ Restart thá»§ cÃ´ng
â†’ Máº¥t ngá»§
```

**Vá»šI KUBERNETES:**
```bash
# Deploy code má»›i (1 command duy nháº¥t!)
kubectl set image deployment/myapp myapp=myapp:v2

# Server/Container cháº¿t
â†’ Kubernetes tá»± Ä‘á»™ng phÃ¡t hiá»‡n
â†’ Tá»± Ä‘á»™ng start container má»›i
â†’ Báº¡n ngá»§ ngon ğŸ˜´
```

### So SÃ¡nh Cá»¥ Thá»ƒ

| TÃ¬nh huá»‘ng | Manual | Kubernetes |
|------------|--------|------------|
| **Deploy 50 containers** | 50 láº§n SSH + commands | 1 command |
| **Container crash** | Thá»©c dáº­y 3 AM restart | Tá»± Ä‘á»™ng restart |
| **Traffic tÄƒng 10x** | Mua server, setup, config (2 ngÃ y) | Tá»± Ä‘á»™ng scale (2 phÃºt) |
| **Rollback version cÅ©** | Revert tá»«ng server (30 phÃºt) | 1 command (10 giÃ¢y) |
| **Load balancing** | Setup nginx/HAProxy manual | Built-in |
| **Health checks** | Viáº¿t scripts riÃªng | Built-in |

---

## ğŸ¯ CÃ¡c TÃ­nh NÄƒng Cá»‘t LÃµi

### 1. Container Orchestration (Äiá»u Phá»‘i Container)

**Táº I SAO Cáº¦N:**
Khi báº¡n cÃ³ 100 containers, khÃ´ng thá»ƒ quáº£n lÃ½ thá»§ cÃ´ng Ä‘Æ°á»£c!

**KUBERNETES LÃ€M GÃŒ:**
```
Báº¡n nÃ³i: "TÃ´i cáº§n 10 containers cháº¡y app nÃ y"
K8s lÃ m:
â”œâ”€â”€ TÃ¬m servers phÃ¹ há»£p
â”œâ”€â”€ Deploy containers
â”œâ”€â”€ Theo dÃµi health
â”œâ”€â”€ Restart náº¿u cháº¿t
â””â”€â”€ Äáº£m báº£o luÃ´n cÃ³ Ä‘á»§ 10 containers
```

**VÃ Dá»¤ THá»°C Táº¾:**
```yaml
# Báº¡n chá»‰ cáº§n nÃ³i:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
spec:
  replicas: 10  # TÃ´i muá»‘n 10 containers

# Kubernetes lo pháº§n cÃ²n láº¡i!
```

---

### 2. Self-Healing (Tá»± Phá»¥c Há»“i)

**Táº I SAO Cáº¦N:**
Server/Container cháº¿t lÃ  chuyá»‡n thÆ°á»ng xuyÃªn. KhÃ´ng thá»ƒ trá»±c 24/7 Ä‘Æ°á»£c!

**KUBERNETES LÃ€M GÃŒ:**
```
Container cháº¿t
    â†“
K8s phÃ¡t hiá»‡n (health check)
    â†“
K8s tá»± Ä‘á»™ng start container má»›i
    â†“
Service tiáº¿p tá»¥c hoáº¡t Ä‘á»™ng
    â†“
User khÃ´ng há» biáº¿t cÃ³ sá»± cá»‘!
```

**VÃ Dá»¤ THá»°C Táº¾:**
```
22:00: Container bá»‹ lá»—i vÃ  crash
22:00:05: Kubernetes phÃ¡t hiá»‡n
22:00:10: Container má»›i Ä‘Ã£ cháº¡y
22:00:15: Service hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng

Báº¡n: Äang ngá»§ ngon ğŸ˜´
User: KhÃ´ng há» biáº¿t cÃ³ sá»± cá»‘
```

---

### 3. Scaling (Má»Ÿ Rá»™ng Tá»± Äá»™ng)

**Táº I SAO Cáº¦N:**
Traffic khÃ´ng Ä‘á»u - sÃ¡ng Ã­t, tá»‘i nhiá»u. Black Friday tÄƒng 100x!

**KUBERNETES LÃ€M GÃŒ:**

**Horizontal Scaling** (tÄƒng sá»‘ lÆ°á»£ng containers):
```
Traffic tháº¥p (8 AM):
  2 containers [â–¡â–¡]

Traffic cao (8 PM):
  10 containers [â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡]

Black Friday:
  50 containers [â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡...â–¡â–¡]
```

**VÃ Dá»¤ THá»°C Táº¾:**
```yaml
# Horizontal Pod Autoscaler
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp
  minReplicas: 2    # Ãt nháº¥t 2 containers
  maxReplicas: 50   # Nhiá»u nháº¥t 50 containers
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Scale khi CPU > 70%
```

**Káº¿t quáº£:**
- CPU tháº¥p â†’ K8s giáº£m xuá»‘ng 2 containers (tiáº¿t kiá»‡m tiá»n)
- CPU cao â†’ K8s tÄƒng lÃªn 50 containers (Ä‘áº£m báº£o performance)
- **Tá»± Ä‘á»™ng, khÃ´ng cáº§n can thiá»‡p!**

---

### 4. Service Discovery & Load Balancing

**Táº I SAO Cáº¦N:**
10 containers backend, frontend cáº§n biáº¿t gá»i container nÃ o?

**KUBERNETES LÃ€M GÃŒ:**
```
Frontend muá»‘n gá»i Backend API
    â†“
Gá»i: http://backend-service
    â†“
Kubernetes tá»± Ä‘á»™ng:
â”œâ”€â”€ TÃ¬m backend containers Ä‘ang healthy
â”œâ”€â”€ PhÃ¢n phá»‘i request Ä‘á»u
â””â”€â”€ Load balance tá»± Ä‘á»™ng

Frontend khÃ´ng cáº§n biáº¿t:
âŒ Backend cháº¡y á»Ÿ server nÃ o
âŒ Backend cÃ³ bao nhiÃªu containers
âŒ IP addresses lÃ  gÃ¬
```

**VÃ Dá»¤ THá»°C Táº¾:**
```yaml
# Service - Kubernetes tá»± Ä‘á»™ng load balance
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 8080

# Frontend chá»‰ cáº§n:
curl http://backend-service/api/users
# Kubernetes lo viá»‡c routing!
```

---

### 5. Rolling Updates & Rollbacks

**Táº I SAO Cáº¦N:**
Deploy code má»›i khÃ´ng Ä‘Æ°á»£c downtime!

**KUBERNETES LÃ€M GÃŒ:**

**Rolling Update** (Update láº§n lÆ°á»£t):
```
Version cÅ©: v1 (10 containers)
[v1][v1][v1][v1][v1][v1][v1][v1][v1][v1]

Step 1: Táº¡o 1 container v2, xÃ³a 1 container v1
[v1][v1][v1][v1][v1][v1][v1][v1][v1][v2]

Step 2: Táº¡o 1 container v2, xÃ³a 1 container v1  
[v1][v1][v1][v1][v1][v1][v1][v1][v2][v2]

...tiáº¿p tá»¥c cho Ä‘áº¿n khi...

Step 10: Táº¥t cáº£ Ä‘Ã£ lÃ  v2
[v2][v2][v2][v2][v2][v2][v2][v2][v2][v2]

âœ“ Zero downtime
âœ“ LuÃ´n cÃ³ containers serving traffic
```

**Rollback náº¿u cÃ³ lá»—i:**
```bash
# Deploy version má»›i
kubectl set image deployment/webapp webapp=myapp:v2

# Oh no! Version v2 cÃ³ bug!
# Rollback vá» version cÅ© (10 giÃ¢y)
kubectl rollout undo deployment/webapp

# Done! Vá» láº¡i version v1 stable
```

---

### 6. Configuration Management

**Táº I SAO Cáº¦N:**
Má»—i mÃ´i trÆ°á»ng (dev, staging, prod) cÃ³ config khÃ¡c nhau.

**KUBERNETES LÃ€M GÃŒ:**
```
ConfigMaps: Non-sensitive config
â”œâ”€â”€ API URLs
â”œâ”€â”€ Feature flags
â”œâ”€â”€ Settings
â””â”€â”€ Environment variables

Secrets: Sensitive data (encrypted)
â”œâ”€â”€ Database passwords
â”œâ”€â”€ API keys
â”œâ”€â”€ Certificates
â””â”€â”€ Tokens
```

**VÃ Dá»¤ THá»°C Táº¾:**
```yaml
# ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  API_URL: "https://api.production.com"
  LOG_LEVEL: "info"
  MAX_CONNECTIONS: "100"

# Secret (encrypted at rest)
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  DB_PASSWORD: cGFzc3dvcmQxMjM=  # base64 encoded

# Sá»­ dá»¥ng trong Pod
apiVersion: v1
kind: Pod
metadata:
  name: myapp
spec:
  containers:
  - name: app
    image: myapp:v1
    envFrom:
    - configMapRef:
        name: app-config
    - secretRef:
        name: app-secrets
```

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Tá»•ng Quan

### Kubernetes Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   KUBERNETES CLUSTER                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚     CONTROL PLANE (Bá»™ nÃ£o)             â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            â”‚
â”‚  â”‚  â”‚  API Server                       â”‚  â”‚            â”‚
â”‚  â”‚  â”‚  (Äiá»ƒm vÃ o duy nháº¥t)             â”‚  â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            â”‚
â”‚  â”‚  â”‚  etcd                            â”‚  â”‚            â”‚
â”‚  â”‚  â”‚  (Database - lÆ°u tráº¡ng thÃ¡i)     â”‚  â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            â”‚
â”‚  â”‚  â”‚  Scheduler                       â”‚  â”‚            â”‚
â”‚  â”‚  â”‚  (Quyáº¿t Ä‘á»‹nh Pod cháº¡y á»Ÿ Ä‘Ã¢u)     â”‚  â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            â”‚
â”‚  â”‚  â”‚  Controller Manager              â”‚  â”‚            â”‚
â”‚  â”‚  â”‚  (Äáº£m báº£o desired state)         â”‚  â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚     WORKER NODES (Thá»£ lÃ m viá»‡c)       â”‚            â”‚
â”‚  â”‚                                        â”‚            â”‚
â”‚  â”‚  Node 1:                               â”‚            â”‚
â”‚  â”‚  â”œâ”€ Pod 1 [Container A, Container B]  â”‚            â”‚
â”‚  â”‚  â”œâ”€ Pod 2 [Container C]                â”‚            â”‚
â”‚  â”‚  â””â”€ Pod 3 [Container D, Container E]  â”‚            â”‚
â”‚  â”‚                                        â”‚            â”‚
â”‚  â”‚  Node 2:                               â”‚            â”‚
â”‚  â”‚  â”œâ”€ Pod 4 [Container F]                â”‚            â”‚
â”‚  â”‚  â””â”€ Pod 5 [Container G]                â”‚            â”‚
â”‚  â”‚                                        â”‚            â”‚
â”‚  â”‚  Node 3:                               â”‚            â”‚
â”‚  â”‚  â”œâ”€ Pod 6 [Container H]                â”‚            â”‚
â”‚  â”‚  â””â”€ Pod 7 [Container I, Container J]  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Workflow Ä‘Æ¡n giáº£n:**
```
1. Báº¡n: "kubectl create deployment webapp --image=myapp:v1"
       â†“
2. API Server: Nháº­n request
       â†“
3. etcd: LÆ°u tráº¡ng thÃ¡i mong muá»‘n
       â†“
4. Scheduler: "Äáº·t Pod nÃ y vÃ o Node 2"
       â†“
5. Controller: "Äáº£m báº£o Pod running"
       â†“
6. Node 2: Download image, start container
       â†“
7. Pod running! âœ…
```

---

## ğŸ“Š So SÃ¡nh: TrÆ°á»›c vs Sau Kubernetes

### Scenario: Deploy Microservices

**TRÆ¯á»šC KUBERNETES:**
```
âŒ 5 services Ã— 3 environments Ã— 4 servers = 60 manual deployments
âŒ Má»—i deploy: 15 phÃºt
âŒ Total: 15 hours (gáº§n 2 ngÃ y lÃ m viá»‡c!)
âŒ Lá»—i 1 server â†’ toÃ n bá»™ process pháº£i lÃ m láº¡i
âŒ Scaling: Pháº£i provision server má»›i (vÃ i giá»)
âŒ Monitoring: 60 nÆ¡i khÃ¡c nhau
```

**Vá»šI KUBERNETES:**
```
âœ… 1 command: kubectl apply -f deployments/
âœ… Má»—i deploy: 5 phÃºt
âœ… Total: 5 phÃºt (nhanh hÆ¡n 180 láº§n!)
âœ… Lá»—i â†’ tá»± Ä‘á»™ng rollback
âœ… Scaling: Tá»± Ä‘á»™ng trong 30 giÃ¢y
âœ… Monitoring: Centralized dashboard
```

---

## ğŸ“ Kiá»ƒm Tra Hiá»ƒu Biáº¿t

### CÃ¢u Há»i Tá»± Kiá»ƒm Tra

**1. Kubernetes giáº£i quyáº¿t váº¥n Ä‘á» gÃ¬?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

- Tá»± Ä‘á»™ng hÃ³a deploy, scaling, management containers
- Self-healing khi cÃ³ lá»—i
- Load balancing tá»± Ä‘á»™ng
- Rolling updates zero-downtime
- Resource management hiá»‡u quáº£
</details>

**2. Self-healing hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

1. Kubernetes liÃªn tá»¥c check health cá»§a containers
2. PhÃ¡t hiá»‡n container khÃ´ng healthy/crashed
3. Tá»± Ä‘á»™ng start container má»›i thay tháº¿
4. Service tiáº¿p tá»¥c hoáº¡t Ä‘á»™ng khÃ´ng giÃ¡n Ä‘oáº¡n
</details>

**3. Horizontal scaling lÃ  gÃ¬? Cho vÃ­ dá»¥.**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

TÄƒng/giáº£m sá»‘ lÆ°á»£ng containers dá»±a trÃªn load:
- Traffic tháº¥p: 2 containers
- Traffic cao: 10 containers
- Black Friday: 50 containers

VÃ­ dá»¥: Web shop bÃ¬nh thÆ°á»ng 5 containers, Black Friday tá»± Ä‘á»™ng scale lÃªn 50 containers.
</details>

**4. Táº¡i sao cáº§n Service trong Kubernetes?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

- Containers cÃ³ IP Ä‘á»™ng, thay Ä‘á»•i liÃªn tá»¥c
- Service cung cáº¥p stable endpoint (DNS name)
- Tá»± Ä‘á»™ng load balance giá»¯a multiple containers
- Service discovery cho cÃ¡c services khÃ¡c
</details>

---

## ğŸ’ª BÃ i Táº­p Thá»±c HÃ nh

### BÃ i 1: Hiá»ƒu Workflow

**TÃ¬nh huá»‘ng:** Báº¡n cÃ³ webapp vá»›i 3 replicas. 1 Pod crash.

**CÃ¢u há»i:** Váº½ flow Kubernetes tá»± Ä‘á»™ng phá»¥c há»“i.

<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

```
1. Pod 2 crash
   [Pod 1] [Pod 2 âŒ] [Pod 3]
   
2. kubelet phÃ¡t hiá»‡n (health check fail)
   
3. kubelet bÃ¡o API Server: "Pod 2 dead"
   
4. Controller Manager tháº¥y: Desired=3, Actual=2
   
5. Controller táº¡o Pod má»›i
   [Pod 1] [Pod 4 ğŸ†•] [Pod 3]
   
6. Scheduler Ä‘áº·t Pod 4 vÃ o Node phÃ¹ há»£p
   
7. Node start Pod 4
   [Pod 1] [Pod 4 âœ…] [Pod 3]
```
</details>

### BÃ i 2: So SÃ¡nh Scenarios

**TÃ¬nh huá»‘ng:** Traffic tÄƒng tá»« 100 req/s â†’ 1000 req/s

**Manual approach:** Báº¡n sáº½ lÃ m gÃ¬?
**Kubernetes approach:** K8s sáº½ lÃ m gÃ¬?

<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

**Manual:**
1. PhÃ¡t hiá»‡n server overload (monitoring)
2. Provision server má»›i (30 phÃºt - vÃ i giá»)
3. Setup OS, dependencies
4. Deploy application
5. Configure load balancer
6. Test
Total: 2-4 giá», rá»§i ro cao

**Kubernetes:**
1. HPA phÃ¡t hiá»‡n CPU > 70%
2. Tá»± Ä‘á»™ng táº¡o thÃªm Pods
3. Scheduler Ä‘áº·t vÃ o Nodes available
4. Service tá»± Ä‘á»™ng load balance
Total: 30 giÃ¢y - 2 phÃºt, tá»± Ä‘á»™ng
</details>

---

## ğŸ¯ Key Takeaways

### Ghi Nhá»› 5 Äiá»u Quan Trá»ng

1. **Kubernetes = Tá»± Ä‘á»™ng hÃ³a quáº£n lÃ½ containers**
   - KhÃ´ng cáº§n lÃ m thá»§ cÃ´ng ná»¯a
   
2. **Self-healing = Ngá»§ ngon hÆ¡n**
   - Container cháº¿t â†’ K8s tá»± restart
   
3. **Scaling = Tiáº¿t kiá»‡m tiá»n + Performance**
   - Tá»± Ä‘á»™ng tÄƒng/giáº£m theo load
   
4. **Rolling updates = Zero downtime**
   - Deploy khÃ´ng áº£nh hÆ°á»Ÿng users
   
5. **Declarative = NÃ³i "muá»‘n gÃ¬", khÃ´ng pháº£i "lÃ m tháº¿ nÃ o"**
   - Báº¡n: "TÃ´i muá»‘n 10 Pods"
   - K8s: "OK, Ä‘á»ƒ tÃ´i lo!"

---

## ğŸ“š Thuáº­t Ngá»¯ Cáº§n Nhá»›

| Thuáº­t Ngá»¯ | Tiáº¿ng Viá»‡t | Ã NghÄ©a |
|-----------|------------|---------|
| **Container** | Container | ÄÃ³ng gÃ³i á»©ng dá»¥ng + dependencies |
| **Pod** | Pod | ÄÆ¡n vá»‹ nhá» nháº¥t, chá»©a 1+ containers |
| **Node** | Node | Server/mÃ¡y áº£o cháº¡y Pods |
| **Cluster** | Cluster | Táº­p há»£p cÃ¡c Nodes |
| **Deployment** | Deployment | Quáº£n lÃ½ Pods, cho phÃ©p rolling updates |
| **Service** | Service | Stable endpoint Ä‘á»ƒ access Pods |
| **Scaling** | Má»Ÿ rá»™ng | TÄƒng/giáº£m sá»‘ lÆ°á»£ng Pods/Nodes |
| **Self-healing** | Tá»± phá»¥c há»“i | Tá»± Ä‘á»™ng thay tháº¿ resources lá»—i |

---

## ğŸš€ Tiáº¿p Theo

Báº¡n Ä‘Ã£ hiá»ƒu Kubernetes lÃ  gÃ¬ vÃ  giáº£i quyáº¿t váº¥n Ä‘á» gÃ¬!

**Next:** [1.2. So SÃ¡nh Kubernetes vs Docker â†’](./02-k8s-vs-docker.md)

á» pháº§n tiáº¿p theo, chÃºng ta sáº½ tÃ¬m hiá»ƒu sá»± khÃ¡c biá»‡t giá»¯a Kubernetes vÃ  Docker, khi nÃ o nÃªn dÃ¹ng cÃ¡i nÃ o.

---

[ğŸ  Má»¥c Lá»¥c ChÃ­nh](../README.md) | [ğŸ“‚ Pháº§n 1: Introduction](./README.md) | [â¡ï¸ 1.2. K8s vs Docker](./02-k8s-vs-docker.md)
