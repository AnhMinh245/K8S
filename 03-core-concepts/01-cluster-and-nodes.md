# 3.1. Cluster vÃ  Nodes

> Hiá»ƒu building blocks cÆ¡ báº£n nháº¥t cá»§a Kubernetes

---

## ğŸ¯ Má»¥c TiÃªu Há»c

Sau khi há»c xong pháº§n nÃ y, báº¡n sáº½:
- âœ… Hiá»ƒu **Cluster vÃ  Node** lÃ  gÃ¬
- âœ… PhÃ¢n biá»‡t **Master Node vs Worker Node**
- âœ… Biáº¿t **Node lifecycle vÃ  management**
- âœ… **Setup local cluster** Ä‘á»ƒ practice
- âœ… Sá»­ dá»¥ng **kubectl commands** cÆ¡ báº£n

---

## ğŸ¢ Cluster LÃ  GÃ¬?

### Äá»‹nh NghÄ©a

**Kubernetes Cluster** = Táº­p há»£p servers (Nodes) lÃ m viá»‡c cÃ¹ng nhau nhÆ° má»™t há»‡ thá»‘ng thá»‘ng nháº¥t.

### Giáº£i ThÃ­ch Báº±ng VÃ­ Dá»¥

**Cluster giá»‘ng nhÆ° má»™t tÃ²a nhÃ  vÄƒn phÃ²ng:**

```
ğŸ¢ TÃ’A NHÃ€ VÄ‚N PHÃ’NG (Cluster)
â”œâ”€â”€ ğŸ¯ Táº§ng Äiá»u HÃ nh (Master Nodes / Control Plane)
â”‚   â”œâ”€â”€ CEO Office (API Server)
â”‚   â”œâ”€â”€ CFO Office (etcd)
â”‚   â”œâ”€â”€ HR Office (Scheduler)
â”‚   â””â”€â”€ Operations Office (Controllers)
â”‚
â””â”€â”€ ğŸ‘· CÃ¡c Táº§ng LÃ m Viá»‡c (Worker Nodes)
    â”œâ”€â”€ Táº§ng 2: Developer teams
    â”œâ”€â”€ Táº§ng 3: QA teams
    â”œâ”€â”€ Táº§ng 4: DevOps teams
    â””â”€â”€ Táº§ng 5+: More teams...
```

### Cluster Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          KUBERNETES CLUSTER                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  Master Nodes (Control Plane):             â”‚
â”‚  â”œâ”€ master-1 (HA setup)                    â”‚
â”‚  â”œâ”€ master-2 (HA setup)                    â”‚
â”‚  â””â”€ master-3 (HA setup)                    â”‚
â”‚                                             â”‚
â”‚  Worker Nodes (Application layer):         â”‚
â”‚  â”œâ”€ worker-1                                â”‚
â”‚  â”œâ”€ worker-2                                â”‚
â”‚  â”œâ”€ worker-3                                â”‚
â”‚  â”œâ”€ worker-4                                â”‚
â”‚  â””â”€ ... more workers ...                   â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ–¥ï¸ Node LÃ  GÃ¬?

### Äá»‹nh NghÄ©a

**Node** = Má»™t server (physical hoáº·c virtual) trong Kubernetes Cluster.

### Loáº¡i Nodes

**1. Master Node (Control Plane Node)**
```
Vai trÃ²: Äiá»u khiá»ƒn vÃ  quáº£n lÃ½ cluster
Cháº¡y: Control Plane components
  â”œâ”€â”€ kube-apiserver
  â”œâ”€â”€ etcd
  â”œâ”€â”€ kube-scheduler
  â””â”€â”€ kube-controller-manager

Sá»‘ lÆ°á»£ng: 
â”œâ”€â”€ 1 node: OK cho dev/test
â”œâ”€â”€ 3 nodes: Recommended cho production (HA)
â””â”€â”€ 5 nodes: Large production clusters

TÃ i nguyÃªn: Ãt hÆ¡n Workers (khÃ´ng cháº¡y apps)
```

**2. Worker Node**
```
Vai trÃ²: Cháº¡y application workloads
Cháº¡y: Node components + Application Pods
  â”œâ”€â”€ kubelet
  â”œâ”€â”€ kube-proxy
  â”œâ”€â”€ Container Runtime
  â””â”€â”€ Application Pods

Sá»‘ lÆ°á»£ng: Nhiá»u (10, 100, 1000+ nodes)
TÃ i nguyÃªn: Nhiá»u CPU/RAM cho applications
```

---

## ğŸ”§ Node Components

### Worker Node Anatomy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           WORKER NODE (worker-1)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  System Info:                                  â”‚
â”‚  â”œâ”€ Hostname: worker-1                         â”‚
â”‚  â”œâ”€ IP: 192.168.1.101                          â”‚
â”‚  â”œâ”€ OS: Ubuntu 22.04                           â”‚
â”‚  â”œâ”€ CPU: 8 cores                               â”‚
â”‚  â”œâ”€ RAM: 32 GB                                 â”‚
â”‚  â””â”€ Disk: 500 GB SSD                           â”‚
â”‚                                                â”‚
â”‚  K8s Components:                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  kubelet (v1.28.0)                       â”‚ â”‚
â”‚  â”‚  â€¢ PID: 1234                             â”‚ â”‚
â”‚  â”‚  â€¢ Managing 15 Pods                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  kube-proxy (v1.28.0)                    â”‚ â”‚
â”‚  â”‚  â€¢ Mode: iptables                        â”‚ â”‚
â”‚  â”‚  â€¢ Managing 50 Services                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Container Runtime: containerd           â”‚ â”‚
â”‚  â”‚  â€¢ Version: 1.7.0                        â”‚ â”‚
â”‚  â”‚  â€¢ Running 25 containers                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â”‚  Pods:                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚Pod1 â”‚ â”‚Pod2 â”‚ â”‚Pod3 â”‚ â”‚... â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Setup Local Cluster

### Option 1: Minikube (Recommended cho beginners)

**Install Minikube:**

```bash
# macOS
brew install minikube

# Linux
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Windows (with Chocolatey)
choco install minikube

# Verify installation
minikube version
```

**Start Cluster:**

```bash
# Start vá»›i default settings
minikube start

# Output:
# ğŸ˜„  minikube v1.32.0 on Darwin 13.5
# âœ¨  Using the docker driver based on existing profile
# ğŸ‘  Starting control plane node minikube in cluster minikube
# ğŸšœ  Pulling base image ...
# ğŸ”¥  Creating docker container (CPUs=2, Memory=4096MB) ...
# ğŸ³  Preparing Kubernetes v1.28.0 on Docker 24.0.6 ...
# ğŸ”—  Configuring bridge CNI (Container Networking Interface) ...
# ğŸ”  Verifying Kubernetes components...
# ğŸŒŸ  Enabled addons: storage-provisioner, default-storageclass
# ğŸ„  Done! kubectl is now configured to use "minikube" cluster

# Check cluster status
minikube status

# Output:
# minikube
# type: Control Plane
# host: Running
# kubelet: Running
# apiserver: Running
# kubeconfig: Configured

# Get cluster info
kubectl cluster-info

# Output:
# Kubernetes control plane is running at https://127.0.0.1:32768
# CoreDNS is running at https://127.0.0.1:32768/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

**Minikube useful commands:**

```bash
# Stop cluster (giá»¯ data)
minikube stop

# Delete cluster (xÃ³a háº¿t)
minikube delete

# SSH vÃ o node
minikube ssh

# Open dashboard
minikube dashboard

# Check resource usage
minikube addons enable metrics-server
kubectl top nodes
```

---

### Option 2: kind (Kubernetes in Docker)

**Install kind:**

```bash
# macOS/Linux
brew install kind

# Linux (binary)
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Verify
kind version
```

**Create Cluster:**

```bash
# Simple single-node cluster
kind create cluster

# Multi-node cluster
cat <<EOF | kind create cluster --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
- role: worker
- role: worker
- role: worker
EOF

# List clusters
kind get clusters

# Get cluster info
kubectl cluster-info --context kind-kind

# Delete cluster
kind delete cluster
```

---

### Option 3: Docker Desktop (Easiest cho Windows/Mac)

```
1. Install Docker Desktop
2. Settings â†’ Kubernetes â†’ Enable Kubernetes
3. Apply & Restart
4. kubectl cluster-info (should work!)
```

---

## ğŸ“Š Working vá»›i Nodes

### View Nodes

```bash
# List all nodes
kubectl get nodes

# Output:
# NAME       STATUS   ROLES           AGE   VERSION
# minikube   Ready    control-plane   5m    v1.28.0

# Detailed node info
kubectl get nodes -o wide

# Output:
# NAME       STATUS   ROLES           AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
# minikube   Ready    control-plane   5m    v1.28.0   192.168.49.2   <none>        Ubuntu 22.04.3 LTS   5.15.0-91-generic   containerd://1.7.10
```

### Describe Node

```bash
# Get detailed information vá» má»™t node
kubectl describe node minikube

# Output (sample):
Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=5883c09216182566a63dff4c326a6fc9ed2982ff
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2024_01_01T10_00_00_0700
                    minikube.k8s.io/version=v1.32.0
                    node-role.kubernetes.io/control-plane=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/containerd/containerd.sock
                    node.alpha.kubernetes.io/ttl: 0
CreationTimestamp:  Mon, 01 Jan 2024 10:00:00 +0700
Taints:             <none>

Conditions:
  Type             Status  LastHeartbeatTime                 Reason                Message
  ----             ------  -----------------                 ------                -------
  MemoryPressure   False   Mon, 01 Jan 2024 10:05:00 +0700  KubeletHasSufficientMemory
  DiskPressure     False   Mon, 01 Jan 2024 10:05:00 +0700  KubeletHasNoDiskPressure
  PIDPressure      False   Mon, 01 Jan 2024 10:05:00 +0700  KubeletHasSufficientPID
  Ready            True    Mon, 01 Jan 2024 10:05:00 +0700  KubeletReady

Capacity:
  cpu:                8
  ephemeral-storage:  488236136Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             32837460Ki
  pods:               110

Allocatable:
  cpu:                8
  ephemeral-storage:  449893134758
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             32735060Ki
  pods:               110

System Info:
  Machine ID:                 abcd1234efgh5678ijkl9012mnop3456
  System UUID:                12345678-1234-1234-1234-123456789012
  Boot ID:                    abcd1234-ab12-cd34-ef56-123456789abc
  Kernel Version:             5.15.0-91-generic
  OS Image:                   Ubuntu 22.04.3 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  containerd://1.7.10
  Kubelet Version:            v1.28.0
  Kube-Proxy Version:         v1.28.0

Non-terminated Pods:          (8 in total)
  Namespace                   Name                                CPU Requests  Memory Requests
  ---------                   ----                                ------------  ---------------
  kube-system                 coredns-5dd5756b68-abc12            100m (1%)     70Mi (0%)
  kube-system                 etcd-minikube                       100m (1%)     100Mi (0%)
  kube-system                 kube-apiserver-minikube             250m (3%)     0 (0%)
  ... more pods ...

Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (10%)  0 (0%)
  memory             470Mi (1%)  370Mi (1%)
```

---

### Node Conditions

**Node Conditions explained:**

```yaml
Conditions:
  # 1. MemoryPressure
  # False = CÃ³ Ä‘á»§ memory
  # True = Memory sáº¯p háº¿t (kubelet sáº½ evict Pods)
  MemoryPressure: False

  # 2. DiskPressure
  # False = CÃ³ Ä‘á»§ disk space
  # True = Disk gáº§n Ä‘áº§y
  DiskPressure: False

  # 3. PIDPressure
  # False = CÃ³ Ä‘á»§ process IDs
  # True = Too many processes
  PIDPressure: False

  # 4. Ready
  # True = Node healthy, cÃ³ thá»ƒ nháº­n Pods
  # False = Node cÃ³ váº¥n Ä‘á»
  # Unknown = kubelet khÃ´ng response (>40s)
  Ready: True
```

---

### Node Capacity vs Allocatable

```
Capacity: Tá»•ng resources cá»§a Node
Allocatable: Resources available cho Pods
          (Capacity - System Reserved - Eviction Thresholds)

Example:
Capacity:
â”œâ”€â”€ CPU: 8 cores
â”œâ”€â”€ Memory: 32 GB
â””â”€â”€ Pods: 110

Allocatable:
â”œâ”€â”€ CPU: 7.8 cores (OS reserved 0.2)
â”œâ”€â”€ Memory: 30 GB (OS + kubelet reserved 2 GB)
â””â”€â”€ Pods: 110
```

---

## ğŸ·ï¸ Node Labels

### Default Labels

```bash
# View node labels
kubectl get nodes --show-labels

# Common default labels:
kubernetes.io/arch=amd64
kubernetes.io/os=linux
kubernetes.io/hostname=worker-1
topology.kubernetes.io/zone=us-central1-a
topology.kubernetes.io/region=us-central1
node.kubernetes.io/instance-type=n1-standard-4
```

### Add Custom Labels

```bash
# Add label
kubectl label nodes worker-1 environment=production
kubectl label nodes worker-1 disktype=ssd

# Verify
kubectl get nodes --show-labels | grep worker-1

# Remove label
kubectl label nodes worker-1 disktype-
```

### Use Labels trong Pod Scheduling

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  # Schedule Pod chá»‰ trÃªn nodes cÃ³ label nÃ y
  nodeSelector:
    disktype: ssd
    environment: production
  containers:
  - name: nginx
    image: nginx
```

---

## ğŸš« Node Taints & Tolerations

### Taints = "Äuá»•i" Pods khá»i Node

```bash
# Add taint (prevent Pods from scheduling)
kubectl taint nodes worker-1 dedicated=database:NoSchedule

# Taint effects:
# NoSchedule: KhÃ´ng schedule Pods má»›i
# PreferNoSchedule: Cá»‘ trÃ¡nh, nhÆ°ng OK náº¿u cáº§n
# NoExecute: Evict existing Pods + khÃ´ng schedule má»›i

# View taints
kubectl describe node worker-1 | grep Taints

# Remove taint
kubectl taint nodes worker-1 dedicated:NoSchedule-
```

### Tolerations = Pods "chá»‹u" Ä‘Æ°á»£c Taint

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: database-pod
spec:
  # Tolerate taint Ä‘á»ƒ schedule Ä‘Æ°á»£c lÃªn node
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "database"
    effect: "NoSchedule"
  containers:
  - name: postgres
    image: postgres:14
```

**Use case:** Dedicate nodes cho specific workloads (databases, GPU jobs)

---

## ğŸ“ Kiá»ƒm Tra Hiá»ƒu Biáº¿t

**1. Cluster vs Node - khÃ¡c nhau nhÆ° tháº¿ nÃ o?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

- **Cluster**: Táº­p há»£p nhiá»u Nodes
- **Node**: Má»™t server trong Cluster

Analogy:
- Cluster = CÃ´ng ty
- Node = NhÃ¢n viÃªn trong cÃ´ng ty
</details>

**2. Master Node vs Worker Node?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

**Master Node:**
- Vai trÃ²: Äiá»u khiá»ƒn cluster
- Cháº¡y: Control Plane components
- Sá»‘ lÆ°á»£ng: 1-5 (HA)

**Worker Node:**
- Vai trÃ²: Cháº¡y applications
- Cháº¡y: kubelet, kube-proxy, Pods
- Sá»‘ lÆ°á»£ng: Nhiá»u (scalable)
</details>

**3. Node Conditions - Ready=False nghÄ©a lÃ  gÃ¬?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

Node cÃ³ váº¥n Ä‘á», khÃ´ng thá»ƒ nháº­n Pods má»›i:
- kubelet khÃ´ng healthy
- Disk/Memory pressure
- Network issues
- Container runtime problems

Cáº§n troubleshoot ngay!
</details>

---

## ğŸ’ª BÃ i Táº­p Thá»±c HÃ nh

### BÃ i 1: Setup vÃ  Explore Cluster

```bash
# 1. Start minikube cluster
minikube start

# 2. Check cluster info
kubectl cluster-info

# 3. Get nodes
kubectl get nodes

# 4. Describe node
kubectl describe node minikube

# Questions:
# - How many nodes?
# - What K8s version?
# - How much CPU/RAM?
# - How many Pods can run?
```

<details>
<summary>Xem sample answers</summary>

```bash
# Nodes: 1 (single-node cluster)
# Version: v1.28.0
# CPU: 8 cores
# RAM: 32 GB
# Max Pods: 110
```
</details>

### BÃ i 2: Node Labels

```bash
# 1. Add labels
kubectl label nodes minikube environment=dev
kubectl label nodes minikube tier=frontend

# 2. Verify labels
kubectl get nodes --show-labels

# 3. Remove a label
kubectl label nodes minikube tier-

# 4. Verify again
kubectl get nodes --show-labels
```

### BÃ i 3: Explore System Pods

```bash
# 1. Get all Pods trong kube-system namespace
kubectl get pods -n kube-system

# 2. Describe má»™t system Pod
kubectl describe pod -n kube-system coredns-<hash>

# 3. Check logs
kubectl logs -n kube-system <pod-name>

# Questions:
# - CÃ¡c system Pods nÃ o Ä‘ang cháº¡y?
# - ChÃºng cháº¡y trÃªn node nÃ o?
# - CÃ³ healthy khÃ´ng?
```

---

## ğŸ¯ Key Takeaways

1. **Cluster = Nhiá»u Nodes**
   - Master Nodes (Control Plane)
   - Worker Nodes (Applications)

2. **Node = Server**
   - Physical hoáº·c Virtual machine
   - Cháº¡y K8s components + Pods

3. **Setup Local Cluster**
   - Minikube: Easiest cho beginners
   - kind: Fast, multi-node
   - Docker Desktop: Integrated

4. **Node Management**
   - Labels: Organize vÃ  select nodes
   - Taints: Control scheduling
   - Conditions: Health status

5. **kubectl Basics**
   - `get nodes`: List nodes
   - `describe node`: Details
   - `label nodes`: Add labels

---

## ğŸš€ Tiáº¿p Theo

Cluster Ä‘Ã£ ready! Giá» há»c vá» Pods - Ä‘Æ¡n vá»‹ cÆ¡ báº£n nháº¥t!

**Next:** [3.2. Pods â†’](./02-pods.md)

---

[â¬…ï¸ Pháº§n 2: Architecture](../02-architecture/README.md) | [ğŸ  Má»¥c Lá»¥c](../README.md) | [ğŸ“‚ Pháº§n 3: Core Concepts](./README.md) | [â¡ï¸ 3.2. Pods](./02-pods.md)
