# 10.4. Service Discovery & Monitoring

> Monitoring tools tá»± Ä‘á»™ng discover targets trong dynamic K8s environment

---

## ğŸ¯ Service Discovery Challenge

**Traditional monitoring (static):**
```
Config file:
  targets:
    - host1:9090
    - host2:9090
    - host3:9090

Problem: Servers come and go â†’ Manual config updates âŒ
```

**K8s monitoring (dynamic):**
```
Pods created/deleted constantly
IPs change on restart
Scale up/down frequently

â†’ Need automatic service discovery! âœ…
```

---

## ğŸ” 1. K8s API as Service Discovery

**Monitoring tools watch K8s API:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      K8s API Server               â”‚
â”‚  â€¢ Pods list/watch                â”‚
â”‚  â€¢ Services list/watch            â”‚
â”‚  â€¢ Endpoints list/watch           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ (watch events)
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monitoring Tool                  â”‚
â”‚  (Datadog / Dynatrace / Prometheus) â”‚
â”‚                                   â”‚
â”‚  1. Watch API for changes         â”‚
â”‚  2. Discover new Pods             â”‚
â”‚  3. Start monitoring              â”‚
â”‚  4. Stop when Pod deleted         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¡ 2. Discovery Methods

### Method 1: Pod Discovery

**Monitor all Pods matching selector:**

```yaml
# Prometheus ServiceMonitor example
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: web-monitor
spec:
  selector:
    matchLabels:
      app: web          # Discover Pods with label app=web
  endpoints:
  - port: metrics       # Port name
    interval: 30s
    path: /metrics
```

**What happens:**
```
1. Prometheus queries K8s API:
   GET /api/v1/pods?labelSelector=app=web

2. K8s returns list of Pods

3. For each Pod:
   - Extract IP: 10.1.1.5
   - Extract port: 9090 (from port name "metrics")
   - Scrape: http://10.1.1.5:9090/metrics

4. Watch for changes:
   - New Pod created â†’ Start monitoring
   - Pod deleted â†’ Stop monitoring
```

---

### Method 2: Service Discovery

**Monitor via Service (more stable):**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"
spec:
  selector:
    app: web
  ports:
  - name: metrics
    port: 9090
    targetPort: 9090
```

**Benefits:**
```
Service endpoints automatically updated:
  â€¢ New Pod added â†’ Endpoint added
  â€¢ Pod deleted â†’ Endpoint removed
  â€¢ Pod not ready â†’ Endpoint removed
  
Monitoring tool scrapes Service endpoints
```

---

### Method 3: Annotations-Based Discovery

**Datadog Autodiscovery:**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: web
  annotations:
    ad.datadoghq.com/check_names: '["nginx"]'
    ad.datadoghq.com/init_configs: '[{}]'
    ad.datadoghq.com/instances: |
      [{
        "nginx_status_url": "http://%%host%%:%%port%%/nginx_status"
      }]
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80
      name: http
```

**Datadog Agent discovers:**
```
1. Watch K8s API for Pods

2. Find Pod with annotation: ad.datadoghq.com/check_names

3. Extract config from annotations

4. Resolve templates:
   %%host%% â†’ Pod IP (10.1.1.5)
   %%port%% â†’ Container port (80)

5. Start check:
   http://10.1.1.5:80/nginx_status
```

---

## ğŸ¯ 3. Endpoints Object

**K8s Endpoints track ready Pods:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080
```

**Corresponding Endpoints:**
```yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: web-service  # Same name as Service
subsets:
- addresses:
  - ip: 10.1.1.5
    nodeName: node-1
    targetRef:
      kind: Pod
      name: web-abc123
      namespace: default
  - ip: 10.1.1.6
    nodeName: node-2
    targetRef:
      kind: Pod
      name: web-xyz789
  ports:
  - port: 8080
    protocol: TCP
```

**Monitoring uses Endpoints:**
```bash
# Get Endpoints
kubectl get endpoints web-service

# Monitoring tool queries:
GET /api/v1/namespaces/default/endpoints/web-service

# Scrape each address:
  http://10.1.1.5:8080/metrics
  http://10.1.1.6:8080/metrics
```

---

## ğŸ”„ 4. Dynamic Updates

**Scenario: Pod scales up:**

```
T=0: Deployment has 2 Pods
  Endpoints: [10.1.1.5, 10.1.1.6]
  Monitoring: Scraping 2 targets

T=1: kubectl scale deployment web --replicas=3
  New Pod created: web-def456 (10.1.1.7)

T=2: Pod becomes Ready
  Endpoints updated: [10.1.1.5, 10.1.1.6, 10.1.1.7]

T=3: Monitoring tool watches Endpoints
  MODIFIED event received
  Add new target: http://10.1.1.7:9090/metrics
  Now scraping 3 targets âœ…
```

---

## ğŸ“Š 5. DNS-Based Discovery

**K8s DNS for service discovery:**

```
Service: web-service.default.svc.cluster.local

DNS query returns:
  â€¢ Service ClusterIP (load balanced)
  â€¢ Or Headless Service â†’ All Pod IPs
```

### Headless Service for Direct Pod Access

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-headless
spec:
  clusterIP: None  # Headless
  selector:
    app: web
  ports:
  - port: 9090
```

**DNS returns all Pod IPs:**
```bash
$ nslookup web-headless.default.svc.cluster.local

Name: web-headless.default.svc.cluster.local
Address: 10.1.1.5
Address: 10.1.1.6
Address: 10.1.1.7
```

**Monitoring scrapes each IP individually:**
```
http://10.1.1.5:9090/metrics
http://10.1.1.6:9090/metrics
http://10.1.1.7:9090/metrics
```

---

## ğŸ”‘ 6. RBAC for Service Discovery

**Monitoring tool needs permissions:**

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: monitoring-discovery
rules:
# Discover Pods
- apiGroups: [""]
  resources:
  - pods
  verbs: ["get", "list", "watch"]

# Discover Services
- apiGroups: [""]
  resources:
  - services
  - endpoints
  verbs: ["get", "list", "watch"]

# Discover Nodes
- apiGroups: [""]
  resources:
  - nodes
  verbs: ["get", "list", "watch"]

# Read config (ConfigMaps with monitoring config)
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]

# Optional: Custom resources (ServiceMonitor, etc.)
- apiGroups: ["monitoring.coreos.com"]
  resources:
  - servicemonitors
  - podmonitors
  verbs: ["get", "list", "watch"]
```

---

## ğŸ¯ 7. Monitoring Target Selection

### Label-Based Filtering

**Only monitor production Pods:**

```yaml
# Prometheus scrape config
scrape_configs:
- job_name: 'kubernetes-pods'
  kubernetes_sd_configs:
  - role: pod
  relabel_configs:
  # Only scrape Pods with label environment=production
  - source_labels: [__meta_kubernetes_pod_label_environment]
    regex: production
    action: keep
  # Only scrape if annotation prometheus.io/scrape=true
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
    regex: "true"
    action: keep
```

---

### Port Selection

**Multiple ports on Pod:**

```yaml
spec:
  containers:
  - name: app
    ports:
    - name: http
      containerPort: 8080
    - name: metrics
      containerPort: 9090
    - name: health
      containerPort: 8081
```

**Scrape specific port:**
```yaml
# Prometheus: Scrape port named "metrics"
endpoints:
- port: metrics  # Port name

# Or by annotation
annotations:
  prometheus.io/port: "9090"  # Port number
```

---

## ğŸ“ˆ 8. Monitoring Multiple Clusters

**Multi-cluster observability:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Central Monitoring (Datadog SaaS)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚         â”‚          â”‚          â”‚
â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”   â”Œâ”€â”€â–¼â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”
â”‚Clusterâ”‚ â”‚Clusterâ”‚ â”‚Clusterâ”‚ â”‚Clusterâ”‚
â”‚ US   â”‚ â”‚ EU    â”‚ â”‚ ASIA  â”‚ â”‚ DEV  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜

Each cluster:
  â€¢ Datadog Agent (DaemonSet)
  â€¢ Cluster Agent (Deployment)
  â€¢ Auto-discover local Pods
  â€¢ Report to central Datadog
  â€¢ Tagged with: cluster, region
```

**Query across clusters:**
```
avg:kubernetes.cpu.usage{cluster:*} by {cluster}

Filter by cluster:
  cluster:us-prod
  cluster:eu-prod
  cluster:asia-prod
```

---

## ğŸ’¡ Best Practices

### âœ… DO

**1. Use annotations for opt-in monitoring**
```yaml
annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9090"
  prometheus.io/path: "/metrics"
```

**2. Name ports for easy discovery**
```yaml
ports:
- name: http
  containerPort: 8080
- name: metrics
  containerPort: 9090
```

**3. Implement readiness probes**
```yaml
readinessProbe:
  httpGet:
    path: /ready
    port: 8080

# Not ready â†’ Removed from Endpoints â†’ Not monitored
```

**4. Label consistently**
```yaml
labels:
  app: web
  environment: production
  tier: frontend

# Easy to filter monitoring targets
```

**5. Use ServiceMonitors (if using Prometheus Operator)**
```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: web-monitor
spec:
  selector:
    matchLabels:
      app: web
  endpoints:
  - port: metrics
```

---

### âŒ DON'T

1. **Monitor every Pod** â†’ Too much data, cost
2. **No labels** â†’ Can't filter
3. **Change ports frequently** â†’ Breaks discovery
4. **No readiness probe** â†’ Monitor unhealthy Pods
5. **Hardcode IPs** â†’ Pods have dynamic IPs!

---

## ğŸ“ Key Takeaways

1. **Service discovery:** Automatic target discovery via K8s API
2. **Endpoints:** Track ready Pods behind Service
3. **Annotations:** Configure monitoring per Pod/Service
4. **Labels:** Filter monitoring targets
5. **RBAC:** Monitoring needs list/watch permissions
6. **Dynamic:** Monitoring adapts as Pods scale
7. **DNS:** Alternative discovery method (Headless Service)

---

## â“ CÃ¢u Há»i Tá»± Kiá»ƒm Tra

1. Monitoring tools discover targets nhÆ° tháº¿ nÃ o?
2. Endpoints object dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?
3. Annotations nÃ o dÃ¹ng cho Prometheus discovery?
4. Táº¡i sao cáº§n readiness probe cho monitoring?
5. RBAC permissions cáº§n cho service discovery?
6. Headless Service khÃ¡c gÃ¬ normal Service?

---

## ğŸš€ Tiáº¿p Theo

ğŸ‘‰ [10.5. Deploying Monitoring Agents](./05-deploying-monitoring-agents.md)

---

[â¬…ï¸ 10.3. Labels](./03-labels-annotations-observability.md) | [â¬†ï¸ Pháº§n 10](./README.md) | [ğŸ  Má»¥c Lá»¥c](../README.md)

