# 2.1. Tá»•ng Quan Kiáº¿n TrÃºc Kubernetes

> Hiá»ƒu big picture trÆ°á»›c khi Ä‘i vÃ o chi tiáº¿t tá»«ng thÃ nh pháº§n

---

## ğŸ¯ Má»¥c TiÃªu Há»c

Sau khi há»c xong pháº§n nÃ y, báº¡n sáº½:
- âœ… Hiá»ƒu **kiáº¿n trÃºc tá»•ng thá»ƒ** cá»§a Kubernetes
- âœ… PhÃ¢n biá»‡t **Control Plane** vÃ  **Worker Node**
- âœ… Hiá»ƒu **communication flow** giá»¯a cÃ¡c components
- âœ… Biáº¿t **vai trÃ²** cá»§a tá»«ng thÃ nh pháº§n chÃ­nh

---

## ğŸ—ï¸ Kubernetes Cluster - Big Picture

### Cluster LÃ  GÃ¬?

**Kubernetes Cluster** = Táº­p há»£p servers lÃ m viá»‡c cÃ¹ng nhau nhÆ° má»™t há»‡ thá»‘ng thá»‘ng nháº¥t.

### Giáº£i ThÃ­ch Báº±ng VÃ­ Dá»¥

**Cluster giá»‘ng nhÆ° má»™t cÃ´ng ty:**

```
ğŸ¢ CÃ´ng Ty (Cluster)
â”œâ”€â”€ ğŸ¯ PhÃ²ng GiÃ¡m Äá»‘c (Control Plane)
â”‚   â”œâ”€â”€ CEO (API Server) - Nháº­n má»i yÃªu cáº§u
â”‚   â”œâ”€â”€ CFO (etcd) - Quáº£n lÃ½ dá»¯ liá»‡u/tráº¡ng thÃ¡i
â”‚   â”œâ”€â”€ HR Manager (Scheduler) - PhÃ¢n cÃ´ng nhÃ¢n viÃªn
â”‚   â””â”€â”€ Operations Manager (Controller Manager) - Äáº£m báº£o má»i thá»© cháº¡y Ä‘Ãºng
â”‚
â””â”€â”€ ğŸ‘· PhÃ²ng Sáº£n Xuáº¥t (Worker Nodes)
    â”œâ”€â”€ Worker Node 1 - NhÃ¢n viÃªn lÃ m viá»‡c
    â”œâ”€â”€ Worker Node 2 - NhÃ¢n viÃªn lÃ m viá»‡c  
    â””â”€â”€ Worker Node 3 - NhÃ¢n viÃªn lÃ m viá»‡c
```

---

## ğŸ“ Kiáº¿n TrÃºc Tá»•ng Thá»ƒ

### Diagram Cluster Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KUBERNETES CLUSTER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         CONTROL PLANE (Bá»™ NÃ£o)                     â”‚    â”‚
â”‚  â”‚         Master Components                          â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚    â”‚
â”‚  â”‚  â”‚ API Server   â”‚  â”‚    etcd      â”‚             â”‚    â”‚
â”‚  â”‚  â”‚ (Äiá»ƒm vÃ o)   â”‚  â”‚ (Database)   â”‚             â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚    â”‚
â”‚  â”‚         â”‚                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚    â”‚
â”‚  â”‚  â”‚  Scheduler    â”‚  â”‚ Controller   â”‚            â”‚    â”‚
â”‚  â”‚  â”‚ (PhÃ¢n cÃ´ng)   â”‚  â”‚  Manager     â”‚            â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ (GiÃ¡m sÃ¡t)   â”‚            â”‚    â”‚
â”‚  â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â†•                                 â”‚
â”‚              [Communication via API]                        â”‚
â”‚                           â†•                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         WORKER NODES (Thá»£ LÃ m Viá»‡c)               â”‚    â”‚
â”‚  â”‚         Data Plane                                 â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  NODE 1                                 â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ kubelet (Agent)                 â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ kube-proxy (Network)            â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ Container Runtime (Docker)      â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  PODS (Applications)            â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”          â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â”‚Pod1â”‚ â”‚Pod2â”‚ â”‚Pod3â”‚          â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜          â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  NODE 2                                 â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ kubelet + kube-proxy + Runtime  â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  PODS: â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”            â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚        â”‚Pod4â”‚ â”‚Pod5â”‚            â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚        â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜            â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  NODE 3                                 â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ kubelet + kube-proxy + Runtime  â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  PODS: â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”    â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚        â”‚Pod6â”‚ â”‚Pod7â”‚ â”‚Pod8â”‚    â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â”‚        â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜    â”‚   â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER/DEVELOPER
      â†“
   kubectl
      â†“
  API Server (Control Plane)
      â†“
  Worker Nodes (Pods running)
```

---

## ğŸ¯ Control Plane vs Worker Nodes

### So SÃ¡nh Chi Tiáº¿t

| Äáº·c Äiá»ƒm | Control Plane | Worker Nodes |
|----------|---------------|--------------|
| **Vai trÃ²** | Bá»™ nÃ£o - Ra quyáº¿t Ä‘á»‹nh | Thá»£ lÃ m viá»‡c - Thá»±c hiá»‡n cÃ´ng viá»‡c |
| **Sá»‘ lÆ°á»£ng** | 1-3 nodes (HA) | Nhiá»u nodes (10, 100, 1000+) |
| **Cháº¡y gÃ¬?** | K8s system components | Application Pods |
| **Quan trá»ng** | Critical - Cháº¿t = cluster cháº¿t | Important - Cháº¿t 1 node OK |
| **TÃ i nguyÃªn** | Ãt CPU/RAM | Nhiá»u CPU/RAM cho apps |
| **Expose** | API Server public | ThÆ°á»ng private |

---

## ğŸ§  Control Plane - Bá»™ NÃ£o

### ThÃ nh Pháº§n ChÃ­nh

**1. API Server (kube-apiserver)**
```
Vai trÃ²: Cá»•ng vÃ o duy nháº¥t cá»§a cluster
VÃ­ dá»¥: Receptionist táº¡i cÃ´ng ty

LÃ m gÃ¬:
â”œâ”€â”€ Nháº­n táº¥t cáº£ requests (kubectl, dashboard, etc.)
â”œâ”€â”€ Authenticate & authorize
â”œâ”€â”€ Validate requests
â””â”€â”€ Forward Ä‘áº¿n components khÃ¡c

Communication:
User â†’ kubectl â†’ API Server â†’ Other components
```

**2. etcd**
```
Vai trÃ²: Database cá»§a cluster
VÃ­ dá»¥: Kho lÆ°u trá»¯ há»“ sÆ¡ cÃ´ng ty

LÆ°u gÃ¬:
â”œâ”€â”€ Cluster state
â”œâ”€â”€ Configuration data
â”œâ”€â”€ Pods Ä‘ang cháº¡y á»Ÿ Ä‘Ã¢u
â”œâ”€â”€ Services cÃ³ nhá»¯ng Endpoints nÃ o
â””â”€â”€ Má»i thÃ´ng tin vá» cluster

Äáº·c Ä‘iá»ƒm:
âœ“ Distributed key-value store
âœ“ Consistent vÃ  highly-available
âœ“ Chá»‰ API Server cÃ³ thá»ƒ Ä‘á»c/ghi
```

**3. Scheduler (kube-scheduler)**
```
Vai trÃ²: Quyáº¿t Ä‘á»‹nh Pod cháº¡y á»Ÿ Node nÃ o
VÃ­ dá»¥: HR Manager phÃ¢n cÃ´ng nhÃ¢n viÃªn

LÃ m gÃ¬:
1. Watch for new Pods (chÆ°a assign Node)
2. Chá»n Node phÃ¹ há»£p nháº¥t dá»±a trÃªn:
   â”œâ”€â”€ Resource available (CPU, RAM)
   â”œâ”€â”€ Node constraints (taints, tolerations)
   â”œâ”€â”€ Affinity/Anti-affinity rules
   â””â”€â”€ Data locality
3. Assign Pod â†’ Node
```

**4. Controller Manager (kube-controller-manager)**
```
Vai trÃ²: Äáº£m báº£o desired state = actual state
VÃ­ dá»¥: Operations Manager giÃ¡m sÃ¡t má»i thá»©

Gá»“m nhiá»u controllers:
â”œâ”€â”€ Node Controller: Watch nodes health
â”œâ”€â”€ Replication Controller: Äáº£m báº£o Ä‘á»§ sá»‘ Pods
â”œâ”€â”€ Endpoints Controller: Populate Endpoints
â”œâ”€â”€ Service Account Controller: Táº¡o default accounts
â””â”€â”€ Nhiá»u controllers khÃ¡c...

Logic: Continuous reconciliation loop
Desired: 3 Pods
Actual: 2 Pods (1 crashed)
â†’ Controller: Táº¡o thÃªm 1 Pod!
```

---

## ğŸ‘· Worker Nodes - Thá»£ LÃ m Viá»‡c

### ThÃ nh Pháº§n ChÃ­nh

**1. kubelet**
```
Vai trÃ²: Agent cháº¡y trÃªn má»—i Node
VÃ­ dá»¥: Supervisor cá»§a má»—i nhÃ¢n viÃªn

LÃ m gÃ¬:
â”œâ”€â”€ Communicate vá»›i API Server
â”œâ”€â”€ Watch for Pods assigned to this Node
â”œâ”€â”€ Start/Stop containers (via Container Runtime)
â”œâ”€â”€ Monitor Pod health
â”œâ”€â”€ Report status vá» API Server
â””â”€â”€ Mount volumes

Äáº·c Ä‘iá»ƒm:
âœ“ Primary "node agent"
âœ“ Cháº¡y trÃªn Má»ŒI node (ká»ƒ cáº£ control plane)
âœ“ KhÃ´ng manage containers khÃ´ng Ä‘Æ°á»£c K8s táº¡o
```

**2. kube-proxy**
```
Vai trÃ²: Network proxy
VÃ­ dá»¥: NhÃ¢n viÃªn bÆ°u Ä‘iá»‡n - Forward thÆ°/gÃ³i hÃ ng

LÃ m gÃ¬:
â”œâ”€â”€ Maintain network rules trÃªn Node
â”œâ”€â”€ Enable Pod-to-Pod communication
â”œâ”€â”€ Implement Service abstraction
â”œâ”€â”€ Load balance traffic Ä‘áº¿n Pods
â””â”€â”€ Support ClusterIP, NodePort, LoadBalancer

Implementation modes:
â”œâ”€â”€ iptables (phá»• biáº¿n)
â”œâ”€â”€ IPVS (performance cao hÆ¡n)
â””â”€â”€ userspace (legacy)
```

**3. Container Runtime**
```
Vai trÃ²: Cháº¡y containers
VÃ­ dá»¥: MÃ¡y mÃ³c Ä‘á»ƒ nhÃ¢n viÃªn lÃ m viá»‡c

Options:
â”œâ”€â”€ Docker (phá»• biáº¿n nháº¥t)
â”œâ”€â”€ containerd (lightweight)
â”œâ”€â”€ CRI-O (OCI-compliant)
â””â”€â”€ Others...

LÃ m gÃ¬:
â”œâ”€â”€ Pull images tá»« registry
â”œâ”€â”€ Start/stop containers
â”œâ”€â”€ Manage container lifecycle
â””â”€â”€ Resource isolation
```

---

## ğŸ”„ Communication Flow - Luá»“ng Hoáº¡t Äá»™ng

### Scenario: Deploy Application

**Step-by-step workflow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. USER CREATES DEPLOYMENT                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
$ kubectl create deployment webapp --image=nginx --replicas=3
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. kubectl â†’ API SERVER                                 â”‚
â”‚     "Táº¡o Deployment vá»›i 3 Pods"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. API SERVER                                           â”‚
â”‚     âœ“ Authenticate user                                  â”‚
â”‚     âœ“ Authorize request                                  â”‚
â”‚     âœ“ Validate Deployment spec                           â”‚
â”‚     âœ“ Write to etcd: "Desired state: 3 Pods"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. DEPLOYMENT CONTROLLER (watching API Server)          â”‚
â”‚     "New Deployment detected!"                           â”‚
â”‚     â†’ Táº¡o ReplicaSet (owner cá»§a Pods)                    â”‚
â”‚     â†’ API Server: "Táº¡o ReplicaSet vá»›i 3 Pods"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. REPLICASET CONTROLLER                                â”‚
â”‚     "New ReplicaSet detected!"                           â”‚
â”‚     â†’ API Server: "Táº¡o 3 Pods"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. API SERVER writes to etcd                            â”‚
â”‚     "3 Pods cáº§n Ä‘Æ°á»£c táº¡o (status: Pending)"             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. SCHEDULER (watching for Pending Pods)                â”‚
â”‚     "3 Pods chÆ°a cÃ³ Node!"                               â”‚
â”‚                                                          â”‚
â”‚     Evaluate Nodes:                                      â”‚
â”‚     Node 1: CPU 40%, RAM 50% âœ“                          â”‚
â”‚     Node 2: CPU 30%, RAM 40% âœ“âœ“ (best fit!)            â”‚
â”‚     Node 3: CPU 60%, RAM 70% âœ“                          â”‚
â”‚                                                          â”‚
â”‚     Decision:                                            â”‚
â”‚     â”œâ”€ Pod1 â†’ Node 2                                     â”‚
â”‚     â”œâ”€ Pod2 â†’ Node 1                                     â”‚
â”‚     â””â”€ Pod3 â†’ Node 2                                     â”‚
â”‚                                                          â”‚
â”‚     â†’ API Server: Update Pod specs vá»›i Node assignment  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. KUBELET on Node 2 (watching API Server)              â”‚
â”‚     "2 Pods assigned to me!"                             â”‚
â”‚                                                          â”‚
â”‚     For each Pod:                                        â”‚
â”‚     1. Pull image: nginx                                 â”‚
â”‚     2. Create container via Container Runtime            â”‚
â”‚     3. Start container                                   â”‚
â”‚     4. Monitor container                                 â”‚
â”‚     5. Report status â†’ API Server                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  9. KUBELET on Node 1 (same process)                     â”‚
â”‚     "1 Pod assigned to me!"                              â”‚
â”‚     â†’ Pull, create, start, monitor                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  10. API SERVER updates etcd                             â”‚
â”‚      Pod1: Running on Node 2 âœ…                          â”‚
â”‚      Pod2: Running on Node 1 âœ…                          â”‚
â”‚      Pod3: Running on Node 2 âœ…                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  11. USER CHECKS STATUS                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
$ kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
webapp-7d8bc4c5d-abc12   1/1     Running   0          30s
webapp-7d8bc4c5d-def34   1/1     Running   0          30s
webapp-7d8bc4c5d-ghi56   1/1     Running   0          30s

âœ… Deployment successful!
```

---

## ğŸ’¡ Táº¡i Sao Kiáº¿n TrÃºc NÃ y?

### Design Principles

**1. Separation of Concerns**
```
Control Plane: Quyáº¿t Ä‘á»‹nh
Worker Nodes: Thá»±c hiá»‡n

Lá»£i Ã­ch:
âœ“ Scale riÃªng biá»‡t
âœ“ Failure isolation
âœ“ Easier maintenance
```

**2. Declarative API**
```
Báº¡n nÃ³i: "TÃ´i muá»‘n 3 Pods"
K8s lÃ m: "OK, Ä‘á»ƒ tÃ´i lo!"

KhÃ´ng cáº§n nÃ³i:
âŒ "Táº¡o Pod1 trÃªn Node1"
âŒ "Táº¡o Pod2 trÃªn Node2"
âŒ "Config networking..."

K8s tá»± Ä‘á»™ng handle táº¥t cáº£!
```

**3. Watch & Reconciliation Loop**
```
Controllers liÃªn tá»¥c:
1. Watch actual state
2. Compare vá»›i desired state
3. Take action náº¿u khÃ¡c nhau
4. Repeat

â†’ Self-healing automatic!
```

**4. API-Driven**
```
Má»i interaction qua API Server:
âœ“ Centralized control
âœ“ Auditable
âœ“ Secure (authn/authz)
âœ“ Extensible
```

---

## ğŸ“ Kiá»ƒm Tra Hiá»ƒu Biáº¿t

### CÃ¢u Há»i Tá»± Kiá»ƒm Tra

**1. Control Plane vÃ  Worker Nodes khÃ¡c nhau nhÆ° tháº¿ nÃ o?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

**Control Plane (Bá»™ nÃ£o):**
- Vai trÃ²: Ra quyáº¿t Ä‘á»‹nh, Ä‘iá»u phá»‘i
- Components: API Server, etcd, Scheduler, Controller Manager
- Cháº¡y: K8s system components
- Quan trá»ng: Critical - cháº¿t = cluster cháº¿t

**Worker Nodes (Thá»£):**
- Vai trÃ²: Thá»±c hiá»‡n cÃ´ng viá»‡c, cháº¡y applications
- Components: kubelet, kube-proxy, Container Runtime
- Cháº¡y: Application Pods
- Redundant: Cháº¿t 1 node, apps váº«n OK trÃªn nodes khÃ¡c
</details>

**2. API Server lÃ m gÃ¬?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

API Server lÃ  cá»•ng vÃ o duy nháº¥t cá»§a cluster:
1. Nháº­n táº¥t cáº£ requests (kubectl, dashboard)
2. Authenticate & authorize
3. Validate requests
4. Write/Read tá»« etcd
5. Forward requests Ä‘áº¿n components khÃ¡c

Analogy: Receptionist/Switchboard operator
</details>

**3. Scheduler quyáº¿t Ä‘á»‹nh Pod cháº¡y á»Ÿ Ä‘Ã¢u dá»±a trÃªn gÃ¬?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

Scheduler evaluate dá»±a trÃªn:
1. **Resource availability**: CPU, RAM available trÃªn node
2. **Resource requests**: Pod cáº§n bao nhiÃªu CPU/RAM
3. **Node constraints**: Taints, tolerations, node selectors
4. **Affinity rules**: Pod muá»‘n/khÃ´ng muá»‘n cháº¡y gáº§n Pod nÃ o
5. **Data locality**: Data á»Ÿ Ä‘Ã¢u (optimize network)
6. **Priority**: Pod nÃ o priority cao hÆ¡n

Choose node cÃ³ score cao nháº¥t!
</details>

**4. Váº½ flow khi báº¡n run `kubectl create deployment`**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

```
kubectl 
  â†’ API Server (validate, write etcd)
    â†’ Deployment Controller (create ReplicaSet)
      â†’ ReplicaSet Controller (create Pods)
        â†’ API Server (write Pods to etcd)
          â†’ Scheduler (assign Pods to Nodes)
            â†’ kubelet on Nodes (create containers)
              â†’ Containers running!
```
</details>

---

## ğŸ’ª BÃ i Táº­p Thá»±c HÃ nh

### BÃ i 1: Identify Components

**TÃ¬nh huá»‘ng:** CÃ¡c components sau thuá»™c Control Plane hay Worker Node?

1. API Server
2. kubelet
3. etcd
4. kube-proxy
5. Scheduler
6. Container Runtime
7. Controller Manager

<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

**Control Plane:**
- API Server âœ“
- etcd âœ“
- Scheduler âœ“
- Controller Manager âœ“

**Worker Node:**
- kubelet âœ“
- kube-proxy âœ“
- Container Runtime âœ“
</details>

---

### BÃ i 2: Trace the Flow

**Pod crash, váº½ flow K8s tá»± phá»¥c há»“i:**

<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

```
1. Container crashes
   â†“
2. kubelet detects (health check fail)
   â†“
3. kubelet reports to API Server
   "Pod X on Node Y is dead"
   â†“
4. API Server writes to etcd
   "Pod X: status = Failed"
   â†“
5. ReplicaSet Controller watches API
   "Desired: 3 Pods, Actual: 2 Pods"
   "Need to create 1 Pod!"
   â†“
6. ReplicaSet Controller â†’ API Server
   "Create new Pod"
   â†“
7. API Server writes to etcd
   "New Pod: status = Pending"
   â†“
8. Scheduler watches for Pending Pods
   "New Pod needs a Node!"
   Evaluate nodes â†’ Choose Node Z
   â†“
9. Scheduler â†’ API Server
   "Assign Pod to Node Z"
   â†“
10. kubelet on Node Z watches API
    "New Pod assigned to me!"
    Pull image â†’ Create container â†’ Start
    â†“
11. kubelet â†’ API Server
    "Pod is Running!"
    â†“
12. Self-healing complete! âœ…
```
</details>

---

## ğŸ¯ Key Takeaways

### Ghi Nhá»› 5 Äiá»u Quan Trá»ng

1. **Cluster = Control Plane + Worker Nodes**
   - Control Plane: Bá»™ nÃ£o (quyáº¿t Ä‘á»‹nh)
   - Worker Nodes: Thá»£ lÃ m viá»‡c (thá»±c hiá»‡n)

2. **API Server = Cá»•ng vÃ o duy nháº¥t**
   - Má»i request Ä‘á»u qua API Server
   - TÆ°Æ¡ng tÃ¡c vá»›i etcd
   - Central hub

3. **etcd = Database cá»§a cluster**
   - LÆ°u má»i state
   - Single source of truth
   - Highly available

4. **Scheduler = PhÃ¢n cÃ´ng thÃ´ng minh**
   - Quyáº¿t Ä‘á»‹nh Pod cháº¡y á»Ÿ Node nÃ o
   - Dá»±a trÃªn resources, constraints, affinity

5. **Controllers = Reconciliation loops**
   - Watch desired vs actual state
   - Take action to match
   - Self-healing mechanism

---

## ğŸ“š Thuáº­t Ngá»¯ Cáº§n Nhá»›

| Thuáº­t Ngá»¯ | Tiáº¿ng Viá»‡t | Ã NghÄ©a |
|-----------|------------|---------|
| **Cluster** | Cluster | Táº­p há»£p servers hoáº¡t Ä‘á»™ng nhÆ° má»™t há»‡ thá»‘ng |
| **Control Plane** | Control Plane | Bá»™ nÃ£o cá»§a cluster (master) |
| **Worker Node** | Worker Node | Server cháº¡y application Pods |
| **API Server** | API Server | Cá»•ng vÃ o duy nháº¥t cá»§a cluster |
| **etcd** | etcd | Database key-value lÆ°u cluster state |
| **Scheduler** | Scheduler | Component phÃ¢n cÃ´ng Pods to Nodes |
| **Controller** | Controller | Component Ä‘áº£m báº£o desired state |
| **kubelet** | kubelet | Agent cháº¡y trÃªn má»—i Node |
| **kube-proxy** | kube-proxy | Network proxy trÃªn má»—i Node |

---

## ğŸš€ Tiáº¿p Theo

Báº¡n Ä‘Ã£ hiá»ƒu kiáº¿n trÃºc tá»•ng thá»ƒ cá»§a Kubernetes!

**Next:** [2.2. Control Plane - Chi Tiáº¿t â†’](./02-control-plane.md)

á» pháº§n tiáº¿p theo, chÃºng ta sáº½ deep dive vÃ o tá»«ng component cá»§a Control Plane, hiá»ƒu chi tiáº¿t cÃ¡ch chÃºng hoáº¡t Ä‘á»™ng.

---

[â¬…ï¸ Pháº§n 1: Introduction](../01-introduction/README.md) | [ğŸ  Má»¥c Lá»¥c ChÃ­nh](../README.md) | [ğŸ“‚ Pháº§n 2: Architecture](./README.md) | [â¡ï¸ 2.2. Control Plane](./02-control-plane.md)
