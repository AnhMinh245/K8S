# 2.3. Worker Node - NÆ¡i Cháº¡y Workload

> Hiá»ƒu cÃ¡ch Worker Node hoáº¡t Ä‘á»™ng vÃ  cháº¡y Pods

---

## ğŸ¯ Má»¥c TiÃªu

- Hiá»ƒu cÃ¡c components trÃªn Worker Node
- Biáº¿t cÃ¡ch kubelet quáº£n lÃ½ Pods
- Náº¯m Ä‘Æ°á»£c Pod lifecycle
- Hiá»ƒu networking trÃªn Node

---

## ğŸ–¥ï¸ Worker Node Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          WORKER NODE (Minion)                â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Pods (Workloads)             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Pod 1   â”‚  â”‚ Pod 2   â”‚  â”‚ Pod 3  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”â”‚ â”‚ â”‚
â”‚  â”‚  â”‚â”‚App    â”‚â”‚  â”‚â”‚Nginx  â”‚â”‚  â”‚â”‚Redis â”‚â”‚ â”‚ â”‚
â”‚  â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â–²                                   â”‚
â”‚          â”‚ (manages)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      kubelet (Node Agent)            â”‚   â”‚ â† Main component
â”‚  â”‚  â€¢ Watch for Pod assignments         â”‚   â”‚
â”‚  â”‚  â€¢ Run containers via CRI            â”‚   â”‚
â”‚  â”‚  â€¢ Report status to API Server       â”‚   â”‚
â”‚  â”‚  â€¢ Health checks                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      kube-proxy                      â”‚   â”‚ â† Networking
â”‚  â”‚  â€¢ Network rules (iptables/IPVS)    â”‚   â”‚
â”‚  â”‚  â€¢ Service load balancing            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Container Runtime                  â”‚   â”‚ â† Run containers
â”‚  â”‚   (Docker / containerd / CRI-O)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚
â”‚  OS: Linux (usually)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1ï¸âƒ£ kubelet

### ğŸ¯ Vai TrÃ²

**kubelet = Node agent, "TrÆ°á»Ÿng ca" táº¡i má»—i Node**

- âœ… **Nháº­n Pod assignments** tá»« API Server
- âœ… **Manage Pod lifecycle** (start, stop, restart)
- âœ… **Health checks** (liveness, readiness probes)
- âœ… **Resource monitoring** (CPU, memory usage)
- âœ… **Report status** vá» API Server

### ğŸ”„ kubelet Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubelet running on Node                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ (poll/watch)
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Server: "Any Pods for this Node?"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ "Yes, run Pod X"
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubelet:                                 â”‚
â”‚  1. Pull container image                â”‚
â”‚  2. Create container via Runtime        â”‚
â”‚  3. Start container                     â”‚
â”‚  4. Setup networking                    â”‚
â”‚  5. Mount volumes                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ (continuous monitoring)
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Health Checks:                           â”‚
â”‚  â€¢ Liveness probe â†’ Restart if failed   â”‚
â”‚  â€¢ Readiness probe â†’ Route traffic or notâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ (report status)
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Server: "Pod X is Running"          â”‚
â”‚             "Pod Y failed health check" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¢ VÃ­ Dá»¥ Thá»±c Táº¿

**kubelet = TrÆ°á»Ÿng ca trong nhÃ  mÃ¡y**

```
Nhiá»‡m vá»¥:
  1. Nháº­n cÃ´ng viá»‡c tá»« vÄƒn phÃ²ng (API Server)
     "HÃ´m nay ca sÃ¡ng cáº§n lÃ m 3 sáº£n pháº©m"
  
  2. Chuáº©n bá»‹ nguyÃªn liá»‡u (pull images)
     "Láº¥y váº­t liá»‡u tá»« kho"
  
  3. Báº¯t Ä‘áº§u sáº£n xuáº¥t (start containers)
     "Khá»Ÿi Ä‘á»™ng mÃ¡y mÃ³c"
  
  4. GiÃ¡m sÃ¡t liÃªn tá»¥c (health checks)
     "Kiá»ƒm tra mÃ¡y mÃ³c cÃ³ hoáº¡t Ä‘á»™ng tá»‘t khÃ´ng"
  
  5. BÃ¡o cÃ¡o tiáº¿n Ä‘á»™ (report status)
     "Sáº£n pháº©m 1 hoÃ n thÃ nh, sáº£n pháº©m 2 Ä‘ang lÃ m..."
  
  6. Xá»­ lÃ½ sá»± cá»‘ (restart failed containers)
     "MÃ¡y 2 há»ng â†’ Restart"
```

### ğŸ”§ kubelet Responsibilities

#### Pod Lifecycle Management
```
Pod lifecycle phases:
  Pending   â†’ kubelet pulls image, prepares
  Running   â†’ Container(s) running
  Succeeded â†’ Completed successfully (Job/CronJob)
  Failed    â†’ Container(s) failed
  Unknown   â†’ Can't determine state
```

#### Health Checks
**1. Liveness Probe:**
```yaml
# Check if container is alive
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  
# If failed 3 times â†’ Restart container
```

**2. Readiness Probe:**
```yaml
# Check if container ready to serve traffic
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
  
# If failed â†’ Remove from Service endpoints
```

**3. Startup Probe:**
```yaml
# For slow-starting containers
startupProbe:
  httpGet:
    path: /startup
    port: 8080
  failureThreshold: 30  # 30 * 10s = 5 minutes timeout
  periodSeconds: 10
```

#### Resource Management
```yaml
resources:
  requests:    # Minimum guaranteed
    cpu: "500m"      # 0.5 CPU core
    memory: "512Mi"  # 512 MB
  limits:      # Maximum allowed
    cpu: "1000m"     # 1 CPU core
    memory: "1Gi"    # 1 GB
```

**kubelet enforces:**
- CPU throttling when limit exceeded
- Container killed (OOMKilled) if memory limit exceeded

#### Volume Management
```
kubelet mounts volumes:
  - emptyDir: Create temporary directory
  - hostPath: Mount from Node filesystem
  - PVC: Mount cloud disk (EBS, GCE PD, etc.)
  - ConfigMap/Secret: Mount as files
```

### ğŸ“Š Status Reporting

**kubelet reports to API Server:**
```
Node status:
  - CPU, memory, disk capacity
  - Running Pods
  - Node conditions (Ready, DiskPressure, MemoryPressure)
  
Pod status:
  - Container states (Running, Waiting, Terminated)
  - Restart counts
  - Resource usage
```

---

## 2ï¸âƒ£ kube-proxy

### ğŸ¯ Vai TrÃ²

**kube-proxy = Network proxy trÃªn má»—i Node**

- âœ… **Service networking** (ClusterIP, NodePort)
- âœ… **Load balancing** giá»¯a Pod replicas
- âœ… **Network rules** (iptables, IPVS, userspace)

### ğŸ¢ VÃ­ Dá»¥ Thá»±c Táº¿

**kube-proxy = Tá»•ng Ä‘Ã i viÃªn**

```
Service "web" cÃ³ 3 Pods backend:
  - Pod A: 10.1.1.5:8080
  - Pod B: 10.1.1.6:8080
  - Pod C: 10.1.1.7:8080

Service ClusterIP: 10.0.0.100:80

kube-proxy táº¡o network rules:
  Request Ä‘áº¿n 10.0.0.100:80
  â†’ Random pick 1 trong 3 Pods
  â†’ Forward request
  
Giá»‘ng tá»•ng Ä‘Ã i viÃªn:
  - KhÃ¡ch gá»i sá»‘ tá»•ng Ä‘Ã i duy nháº¥t
  - Tá»•ng Ä‘Ã i chuyá»ƒn Ä‘áº¿n nhÃ¢n viÃªn ráº£nh
```

### ğŸ”§ kube-proxy Modes

#### 1. iptables Mode (Default, phá»• biáº¿n nháº¥t)
```bash
# kube-proxy creates iptables rules
# Example: Service "web" with ClusterIP 10.0.0.100

# Rule 1: Intercept traffic to ClusterIP
iptables -A KUBE-SERVICES \
  -d 10.0.0.100/32 -p tcp --dport 80 \
  -j KUBE-SVC-WEB

# Rule 2: Load balance to Pods (random)
iptables -A KUBE-SVC-WEB -m statistic --mode random --probability 0.33 \
  -j KUBE-SEP-POD-A  # 10.1.1.5:8080

iptables -A KUBE-SVC-WEB -m statistic --mode random --probability 0.50 \
  -j KUBE-SEP-POD-B  # 10.1.1.6:8080

iptables -A KUBE-SVC-WEB \
  -j KUBE-SEP-POD-C  # 10.1.1.7:8080 (default)
```

**Pros:**
- Mature, stable
- Low overhead

**Cons:**
- Doesn't scale well (1000s of services)
- No real load balancing (just random)

#### 2. IPVS Mode (Recommended for large clusters)
```
Uses Linux IPVS (IP Virtual Server):
  - Better performance
  - More load balancing algorithms:
    â€¢ Round-robin
    â€¢ Least connection
    â€¢ Source hashing
  - Scales to 10,000+ services
```

#### 3. userspace Mode (Legacy, deprecated)
```
kube-proxy itself proxies traffic:
  - Performance overhead
  - Not recommended
```

### ğŸŒ Service Types Handling

**ClusterIP:**
```
Service: 10.0.0.100 (cluster-internal IP)
kube-proxy: Create rules to forward to Pod IPs
```

**NodePort:**
```
Service: 10.0.0.100 + NodePort 30080
kube-proxy: 
  - Listen on Node IP:30080
  - Forward to Pod IPs
  
Access from outside:
  http://NodeIP:30080 â†’ Pod
```

**LoadBalancer:**
```
Cloud LB: 203.0.113.5
  â†“
NodePort: 30080 (created automatically)
  â†“
kube-proxy forwards to Pods
```

---

## 3ï¸âƒ£ Container Runtime

### ğŸ¯ Vai TrÃ²

**Container Runtime = "Äá»™ng cÆ¡" cháº¡y containers**

- âœ… **Pull images** tá»« registry
- âœ… **Create containers** tá»« images
- âœ… **Start/Stop containers**
- âœ… **Isolate containers** (namespaces, cgroups)

### ğŸ”„ CRI (Container Runtime Interface)

**Kubernetes khÃ´ng phá»¥ thuá»™c Docker:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   kubelet    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (CRI - gRPC API)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Container Runtime              â”‚
â”‚   â€¢ Docker (via dockershim)      â”‚ â† Deprecated
â”‚   â€¢ containerd â­                 â”‚ â† Recommended
â”‚   â€¢ CRI-O                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ³ Runtime Options

#### 1. containerd (Recommended)
```
Lightweight, native K8s runtime
  - Graduated from Docker
  - Industry standard
  - Used by Docker itself

Installation:
  Most managed K8s (EKS, GKE, AKS) use containerd
```

#### 2. CRI-O
```
Designed specifically for K8s
  - Lightweight
  - OCI-compliant
  - Minimal

Use case:
  - Red Hat OpenShift
  - Embedded systems
```

#### 3. Docker (via dockershim - DEPRECATED)
```
Legacy support:
  - dockershim removed in K8s 1.24+
  - Use containerd instead

Migration:
  Docker images still work!
  Only runtime changes, not image format
```

---

## ğŸ“¦ Pod Lifecycle On Node

### Full Flow

```
1. Scheduler assigns Pod to Node
   API Server: Update Pod.spec.nodeName = "node-1"

2. kubelet (on node-1) detects assignment
   kubelet watches: "New Pod for me!"

3. kubelet pulls image
   kubelet â†’ Container Runtime: "Pull nginx:1.21"
   Runtime â†’ Docker Hub: Download image

4. kubelet creates Pod sandbox
   Setup network namespace, IPC, etc.

5. kubelet starts init containers (if any)
   Wait for init containers to complete

6. kubelet starts main containers
   Container Runtime: Start nginx container

7. kubelet runs readiness probe
   Wait until app is ready

8. kubelet updates Pod status
   kubelet â†’ API Server: "Pod is Running"

9. Continuous monitoring
   - Liveness probe every 10s
   - Resource usage monitoring
   - Log collection

10. Pod termination (when deleted)
    1. Send SIGTERM to containers
    2. Wait gracefully (default 30s)
    3. Send SIGKILL if still running
    4. Cleanup resources
```

### ğŸ” Example: Pod Startup

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: web-app
spec:
  initContainers:
  - name: init-db
    image: busybox
    command: ['sh', '-c', 'until nc -z db:3306; do sleep 1; done']
  
  containers:
  - name: app
    image: nginx:1.21
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /healthz
        port: 80
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      periodSeconds: 5
```

**Execution:**
```
1. kubelet pulls busybox image
2. kubelet starts init-db container
3. init-db waits for DB (may take 30s)
4. init-db exits successfully
5. kubelet pulls nginx:1.21 image
6. kubelet starts app container
7. Wait 30s (initialDelaySeconds)
8. Start liveness probe (every 10s)
9. Start readiness probe (every 5s)
10. When readiness passes â†’ Add to Service
```

---

## ğŸ”— Node Components Interaction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Control Plane                  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ API Server â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ (1) Watch for Pod assignments
         â”‚ (2) Report Node/Pod status
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    Worker Node          â”‚
â”‚ â”‚   kubelet   â”‚                         â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚        â”‚                                â”‚
â”‚        â”‚ (3) Create Pod                 â”‚
â”‚        â–¼                                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚ â”‚Container Runtimeâ”‚                     â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚          â”‚                              â”‚
â”‚          â”‚ (4) Start containers         â”‚
â”‚          â–¼                              â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚      â”‚  Pods  â”‚                         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚          â–²                              â”‚
â”‚          â”‚                              â”‚
â”‚          â”‚ (5) Network traffic          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚    â”‚ kube-proxy â”‚                       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚        â†‘                                â”‚
â”‚        â”‚ (6) Watch Services/Endpoints   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   Control Plane          â”‚
â”‚  â”‚ API Serverâ”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Key Takeaways

1. **kubelet:** Node agent, manages Pods, health checks
2. **kube-proxy:** Network proxy, Service load balancing
3. **Container Runtime:** Actual container execution (containerd recommended)
4. **Pod lifecycle:** Pull â†’ Create â†’ Start â†’ Monitor â†’ Report
5. **Health probes:** Liveness (restart), Readiness (traffic routing)
6. **Async communication:** Components watch API Server
7. **Node = Worker:** Executes workloads, reports status

---

## â“ CÃ¢u Há»i Tá»± Kiá»ƒm Tra

1. kubelet lÃ m gÃ¬ khi Ä‘Æ°á»£c assign má»™t Pod?
2. Sá»± khÃ¡c biá»‡t giá»¯a liveness vÃ  readiness probe?
3. kube-proxy lÃ m gÃ¬ vá»›i Service?
4. Container Runtime nÃ o Ä‘Æ°á»£c recommend?
5. Váº½ flow tá»« khi Pod Ä‘Æ°á»£c assign Ä‘áº¿n khi Running

---

## ğŸš€ Tiáº¿p Theo

Báº¡n Ä‘Ã£ hoÃ n thÃ nh **Pháº§n 2: Architecture**! ğŸ‰

ğŸ‘‰ [**Pháº§n 3: Core Concepts - KhÃ¡i Niá»‡m Cá»‘t LÃµi**](../03-core-concepts/README.md)

---

[â¬…ï¸ 2.2. Control Plane](./02-control-plane.md) | [â¬†ï¸ Pháº§n 2](./README.md) | [ğŸ  Má»¥c Lá»¥c ChÃ­nh](../README.md)


