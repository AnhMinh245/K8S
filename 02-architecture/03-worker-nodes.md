# 2.3. Worker Nodes - NÆ¡i Cháº¡y Applications

> Deep dive vÃ o Worker Nodes - nÆ¡i workloads thá»±c sá»± cháº¡y

---

## ğŸ¯ Má»¥c TiÃªu Há»c

Sau khi há»c xong pháº§n nÃ y, báº¡n sáº½:
- âœ… Hiá»ƒu **chi tiáº¿t cÃ¡c components** trÃªn Worker Node
- âœ… Biáº¿t **cÃ¡ch kubelet quáº£n lÃ½ Pods**
- âœ… Hiá»ƒu **networking trong Node** (kube-proxy)
- âœ… Troubleshoot Ä‘Æ°á»£c **Node-level issues**

---

## ğŸ‘· Worker Node Components

### Tá»•ng Quan

```
WORKER NODE = NÆ I APPLICATIONS CHáº Y

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            WORKER NODE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. kubelet                              â”‚ â”‚
â”‚  â”‚     â€¢ Node agent                         â”‚ â”‚
â”‚  â”‚     â€¢ Manage Pods lifecycle              â”‚ â”‚
â”‚  â”‚     â€¢ Report to API Server               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  2. kube-proxy                           â”‚ â”‚
â”‚  â”‚     â€¢ Network proxy                      â”‚ â”‚
â”‚  â”‚     â€¢ Service load balancing             â”‚ â”‚
â”‚  â”‚     â€¢ Maintain iptables rules            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  3. Container Runtime                    â”‚ â”‚
â”‚  â”‚     â€¢ Docker / containerd / CRI-O        â”‚ â”‚
â”‚  â”‚     â€¢ Pull images, run containers        â”‚ â”‚
â”‚  â”‚     â€¢ Manage container lifecycle         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  PODS (Running Applications)             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”           â”‚ â”‚
â”‚  â”‚  â”‚ Pod1 â”‚  â”‚ Pod2 â”‚  â”‚ Pod3 â”‚           â”‚ â”‚
â”‚  â”‚  â”‚â”Œâ”€â”€â”€â”€â”â”‚  â”‚â”Œâ”€â”€â”€â”€â”â”‚  â”‚â”Œâ”€â”€â”€â”€â”â”‚           â”‚ â”‚
â”‚  â”‚  â”‚â”‚App â”‚â”‚  â”‚â”‚App â”‚â”‚  â”‚â”‚App â”‚â”‚           â”‚ â”‚
â”‚  â”‚  â”‚â””â”€â”€â”€â”€â”˜â”‚  â”‚â””â”€â”€â”€â”€â”˜â”‚  â”‚â””â”€â”€â”€â”€â”˜â”‚           â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Operating System (Linux)                â”‚ â”‚
â”‚  â”‚  â€¢ Kernel                                â”‚ â”‚
â”‚  â”‚  â€¢ cgroups (resource limits)             â”‚ â”‚
â”‚  â”‚  â€¢ namespaces (isolation)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1ï¸âƒ£ kubelet - Node Agent

### Vai TrÃ²: Supervisor Cá»§a Node

**kubelet = Foreman/Supervisor táº¡i construction site**

```
kubelet responsibilities:
â”œâ”€â”€ Watch API Server for Pods assigned to this Node
â”œâ”€â”€ Ensure containers are running in Pods
â”œâ”€â”€ Mount volumes
â”œâ”€â”€ Run health checks (liveness, readiness)
â”œâ”€â”€ Report Pod & Node status to API Server
â””â”€â”€ Execute lifecycle hooks
```

### Kubelet Workflow

**Complete lifecycle management:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KUBELET POD LIFECYCLE MANAGEMENT                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. WATCH API SERVER
   â†“
   "New Pod assigned to me!"
   Pod: webapp-abc123
   Image: nginx:latest
   â†“

2. CHECK POD STATUS
   â†“
   Pod not exist locally? â†’ Need to create
   â†“

3. PULL IMAGE (via Container Runtime)
   â†“
   kubelet â†’ Container Runtime: "Pull nginx:latest"
   Container Runtime â†’ Docker Hub: Download image
   â†“
   [====== Downloading ======] 100%
   Image stored: /var/lib/containerd/...
   â†“

4. CREATE CONTAINER(S)
   â†“
   kubelet â†’ Container Runtime: "Create container"
   Parameters:
   â”œâ”€â”€ Image: nginx:latest
   â”œâ”€â”€ Command: [nginx, -g, daemon off;]
   â”œâ”€â”€ Env vars: DB_HOST=postgres
   â”œâ”€â”€ Volumes: /data â†’ emptyDir
   â”œâ”€â”€ Resources: CPU 500m, RAM 256Mi
   â””â”€â”€ Network: Pod network
   â†“

5. START CONTAINER
   â†“
   Container Runtime: Start container
   Container ID: abc123def456
   Container state: Running
   â†“

6. MONITOR HEALTH
   â†“
   Every 10s:
   â”œâ”€â”€ Liveness probe: GET http://localhost/health
   â”‚   Response 200 OK â†’ Healthy âœ“
   â”œâ”€â”€ Readiness probe: GET http://localhost/ready
   â”‚   Response 200 OK â†’ Ready âœ“
   â””â”€â”€ Container state: Running
   â†“

7. REPORT STATUS to API Server
   â†“
   kubelet â†’ API Server:
   {
     "podIP": "10.244.1.5",
     "phase": "Running",
     "conditions": [
       {"type": "Ready", "status": "True"},
       {"type": "ContainersReady", "status": "True"}
     ],
     "containerStatuses": [
       {
         "name": "nginx",
         "state": {"running": {"startedAt": "..."}},
         "ready": true
       }
     ]
   }
   â†“

8. CONTINUOUS MONITORING
   â†“
   Every iteration:
   â”œâ”€â”€ Check container still running
   â”œâ”€â”€ Run health probes
   â”œâ”€â”€ Monitor resource usage
   â”œâ”€â”€ Report status
   â””â”€â”€ React to changes (Pod deleted? Stop containers!)
```

### Kubelet Configuration

**Key kubelet parameters:**

```bash
# /var/lib/kubelet/config.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration

# API Server connection
clusterDomain: cluster.local
clusterDNS:
  - 10.96.0.10

# Pod management
podCIDR: 10.244.1.0/24
maxPods: 110

# Resource management
cpuManagerPolicy: none
memoryManagerPolicy: None

# Health checks
nodeStatusUpdateFrequency: 10s
nodeStatusReportFrequency: 5m

# Eviction thresholds
evictionHard:
  memory.available: "100Mi"
  nodefs.available: "10%"
  imagefs.available: "15%"

# Image management
imageGCHighThresholdPercent: 85
imageGCLowThresholdPercent: 80
```

### Kubelet Interaction vá»›i Container Runtime

**CRI (Container Runtime Interface):**

```
kubelet â†--CRI API--â†’ Container Runtime
                      â”œâ”€â”€ Docker (via dockershim - deprecated)
                      â”œâ”€â”€ containerd âœ“ (recommended)
                      â”œâ”€â”€ CRI-O âœ“
                      â””â”€â”€ Others...

CRI Operations:
â”œâ”€â”€ RunPodSandbox (create Pod network namespace)
â”œâ”€â”€ CreateContainer (create container in Pod)
â”œâ”€â”€ StartContainer (start container)
â”œâ”€â”€ StopContainer (stop container)
â”œâ”€â”€ RemoveContainer (cleanup)
â””â”€â”€ ListContainers (list running containers)
```

**Example: Create Pod via CRI**

```
1. kubelet â†’ CRI: RunPodSandbox
   Create Pod network namespace
   Assign Pod IP: 10.244.1.5
   â†“

2. kubelet â†’ CRI: CreateContainer
   Container spec: {
     image: "nginx:latest",
     command: ["nginx"],
     env: [...],
     mounts: [...]
   }
   â†“

3. CRI â†’ containerd: Create container
   containerd creates container
   Returns containerID: abc123
   â†“

4. kubelet â†’ CRI: StartContainer(abc123)
   CRI â†’ containerd: Start
   Container running!
   â†“

5. kubelet monitors container
   Continuously checks health
```

---

## 2ï¸âƒ£ kube-proxy - Network Proxy

### Vai TrÃ²: Network Traffic Manager

**kube-proxy = Traffic cop/Router trong Node**

```
kube-proxy lÃ m gÃ¬:
â”œâ”€â”€ Maintain network rules trÃªn Node
â”œâ”€â”€ Enable Service abstraction
â”œâ”€â”€ Load balance traffic to Pods
â”œâ”€â”€ Implement ClusterIP, NodePort, LoadBalancer
â””â”€â”€ Handle Pod-to-Pod communication
```

### Service Implementation

**CÃ¡ch kube-proxy implement Services:**

```yaml
# Service definition
apiVersion: v1
kind: Service
metadata:
  name: webapp
spec:
  selector:
    app: webapp
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP
```

**kube-proxy táº¡o rules:**

**Mode 1: iptables (default, phá»• biáº¿n nháº¥t)**

```bash
# kube-proxy táº¡o iptables rules

# Service ClusterIP: 10.96.100.50
# Backend Pods:
# - Pod1: 10.244.1.5:8080
# - Pod2: 10.244.2.8:8080
# - Pod3: 10.244.1.9:8080

# iptables rules (simplified):
iptables -A KUBE-SERVICES \
  -d 10.96.100.50/32 -p tcp --dport 80 \
  -j KUBE-SVC-WEBAPP

# Load balance to 3 Pods
iptables -A KUBE-SVC-WEBAPP \
  -m statistic --mode random --probability 0.33 \
  -j KUBE-SEP-POD1

iptables -A KUBE-SVC-WEBAPP \
  -m statistic --mode random --probability 0.50 \
  -j KUBE-SEP-POD2

iptables -A KUBE-SVC-WEBAPP \
  -j KUBE-SEP-POD3

# DNAT to actual Pod IPs
iptables -A KUBE-SEP-POD1 -j DNAT --to-destination 10.244.1.5:8080
iptables -A KUBE-SEP-POD2 -j DNAT --to-destination 10.244.2.8:8080
iptables -A KUBE-SEP-POD3 -j DNAT --to-destination 10.244.1.9:8080
```

**Traffic flow:**

```
Application calls Service:
curl http://webapp:80
    â†“
DNS resolves: webapp â†’ 10.96.100.50 (ClusterIP)
    â†“
Kernel hits iptables rules:
DNAT to one of backend Pods (random)
    â†“
Options (33% / 33% / 34%):
â”œâ”€â”€ 10.244.1.5:8080 (Pod1)
â”œâ”€â”€ 10.244.2.8:8080 (Pod2)
â””â”€â”€ 10.244.1.9:8080 (Pod3)
    â†“
Traffic reaches Pod
    â†“
Pod processes request
    â†“
Response back to caller
```

**Mode 2: IPVS (IP Virtual Server - better performance)**

```bash
# kube-proxy creates IPVS virtual server

# Install ipvsadm to view
ipvsadm -Ln

# Output:
IP Virtual Server version 1.2.1
TCP  10.96.100.50:80 rr  (round-robin)
  -> 10.244.1.5:8080      Masq    1      0          0
  -> 10.244.2.8:8080      Masq    1      0          0
  -> 10.244.1.9:8080      Masq    1      0          0

# Load balancing algorithms:
# - rr (round-robin)
# - lc (least connection)
# - dh (destination hashing)
# - sh (source hashing)
```

**IPVS advantages:**
```
vs iptables:
âœ“ Better performance (O(1) vs O(n))
âœ“ More load balancing algorithms
âœ“ Better for large clusters (1000+ services)
âœ— Requires kernel modules
```

### NodePort Implementation

**Example:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp
spec:
  type: NodePort
  selector:
    app: webapp
  ports:
  - port: 80
    targetPort: 8080
    nodePort: 30080  # Exposed on all Nodes
```

**kube-proxy rules:**

```bash
# Listen on NodePort 30080 on ALL Node IPs
# Node1 IP: 192.168.1.10
# Node2 IP: 192.168.1.11
# Node3 IP: 192.168.1.12

# iptables rules:
iptables -A KUBE-NODEPORTS \
  -p tcp --dport 30080 \
  -j KUBE-SVC-WEBAPP

# Then same load balancing as ClusterIP
```

**Traffic flow:**

```
External user:
curl http://192.168.1.10:30080
    â†“
Hits Node1 on port 30080
    â†“
iptables DNAT to Pod IP
    â†“
Pod on ANY node (could be Node2!)
    â†“
Response back through Node1
```

---

## 3ï¸âƒ£ Container Runtime

### Vai TrÃ²: Cháº¡y Containers

**Container Runtime = Engine cháº¡y containers**

```
Container Runtime options:
â”œâ”€â”€ Docker (legacy, deprecated in K8s 1.24+)
â”œâ”€â”€ containerd âœ“ (recommended, default in many distros)
â”œâ”€â”€ CRI-O âœ“ (lightweight, OCI-compliant)
â””â”€â”€ Others (kata, gVisor for security)
```

### containerd Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CONTAINERD                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CRI Plugin (gRPC)                   â”‚  â”‚
â”‚  â”‚  â€¢ Implements CRI                    â”‚  â”‚
â”‚  â”‚  â€¢ Interface for kubelet             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â†“                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  containerd Core                     â”‚  â”‚
â”‚  â”‚  â€¢ Image management                  â”‚  â”‚
â”‚  â”‚  â€¢ Container lifecycle               â”‚  â”‚
â”‚  â”‚  â€¢ Snapshots                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â†“                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  runc (OCI Runtime)                  â”‚  â”‚
â”‚  â”‚  â€¢ Low-level container runtime       â”‚  â”‚
â”‚  â”‚  â€¢ Create & run containers           â”‚  â”‚
â”‚  â”‚  â€¢ cgroups & namespaces              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LINUX KERNEL                        â”‚
â”‚  â€¢ Namespaces (isolation)                   â”‚
â”‚  â€¢ cgroups (resource limits)                â”‚
â”‚  â€¢ Capabilities                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Container Lifecycle

**From image to running container:**

```
1. PULL IMAGE
   containerd â†’ Registry (Docker Hub):
   "Download nginx:latest"
   â†“
   Layers downloaded:
   â”œâ”€â”€ Layer 1: base OS
   â”œâ”€â”€ Layer 2: nginx binary
   â”œâ”€â”€ Layer 3: config files
   â””â”€â”€ Layer 4: entry point
   â†“
   Stored in: /var/lib/containerd/...
   â†“

2. CREATE CONTAINER
   containerd creates container config:
   {
     "image": "nginx:latest",
     "rootfs": "/var/lib/containerd/...",
     "env": ["PATH=/usr/bin"],
     "cmd": ["nginx", "-g", "daemon off;"],
     "mounts": [...],
     "namespaces": [
       {"type": "pid"},
       {"type": "network"},
       {"type": "mount"},
       {"type": "uts"}
     ],
     "cgroups": {
       "cpu": {"quota": 50000},  # 500m CPU
       "memory": {"limit": 268435456}  # 256Mi
     }
   }
   â†“

3. START CONTAINER
   runc creates:
   â”œâ”€â”€ New namespaces (isolation)
   â”œâ”€â”€ cgroups (resource limits)
   â”œâ”€â”€ Root filesystem (from image layers)
   â””â”€â”€ Network namespace
   â†“
   Execute entrypoint: nginx -g "daemon off;"
   â†“
   Container PID: 12345
   Container running!
   â†“

4. MONITOR
   containerd monitors:
   â”œâ”€â”€ Process state (running/stopped)
   â”œâ”€â”€ Resource usage (CPU, RAM)
   â””â”€â”€ Exit code if stopped
```

---

## ğŸ”„ Node Components Interaction

### Complete Flow: Pod Startup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POD STARTUP ON WORKER NODE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. SCHEDULER assigns Pod to Node
   API Server: Pod.spec.nodeName = "worker-node-1"
   â†“

2. KUBELET on worker-node-1 watches API Server
   "New Pod assigned to me!"
   Pod: webapp-abc123
   â†“

3. KUBELET â†’ CONTAINER RUNTIME (via CRI)
   "Create Pod sandbox"
   â†“
   Container Runtime:
   â”œâ”€â”€ Create network namespace
   â”œâ”€â”€ Setup Pod network (assign IP)
   â”œâ”€â”€ Pod IP: 10.244.1.5
   â””â”€â”€ Return sandbox ID
   â†“

4. KUBELET â†’ CONTAINER RUNTIME
   "Pull image: nginx:latest"
   â†“
   Container Runtime downloads image
   [====== Download 100% ======]
   â†“

5. KUBELET â†’ CONTAINER RUNTIME
   "Create container in sandbox"
   â†“
   Container Runtime:
   â”œâ”€â”€ Create container from image
   â”œâ”€â”€ Mount volumes
   â”œâ”€â”€ Set environment variables
   â”œâ”€â”€ Configure resources (CPU, RAM limits)
   â””â”€â”€ Return container ID
   â†“

6. KUBELET â†’ CONTAINER RUNTIME
   "Start container"
   â†“
   Container Runtime starts container
   Container state: Running
   â†“

7. KUBELET configures KUBE-PROXY
   (via updating Endpoints)
   â†“

8. KUBE-PROXY updates iptables/IPVS
   Add Pod IP to Service backend pool
   Service: webapp
   Backend Pods:
   â”œâ”€â”€ 10.244.1.5:8080 â† NEW!
   â”œâ”€â”€ 10.244.2.8:8080
   â””â”€â”€ 10.244.1.9:8080
   â†“

9. KUBELET runs health checks
   Liveness: GET http://10.244.1.5:8080/health
   Response: 200 OK âœ“
   â†“
   Readiness: GET http://10.244.1.5:8080/ready  
   Response: 200 OK âœ“
   â†“

10. KUBELET â†’ API SERVER
    "Pod ready!"
    Pod status:
    â”œâ”€â”€ phase: Running
    â”œâ”€â”€ conditions: Ready=True
    â”œâ”€â”€ podIP: 10.244.1.5
    â””â”€â”€ containerStatuses: [...ready...]
    â†“

11. Pod fully operational! âœ…
    Receiving traffic from Service
```

---

## ğŸ” Troubleshooting Worker Nodes

### Common Issues & Solutions

**Issue 1: Node NotReady**

```bash
# Check Node status
kubectl get nodes
NAME           STATUS     ROLES    AGE   VERSION
worker-node-1  NotReady   <none>   5d    v1.28.0

# Describe Node
kubectl describe node worker-node-1
# Look at conditions and events

# Common causes:
# 1. kubelet not running
ssh worker-node-1
sudo systemctl status kubelet
sudo systemctl restart kubelet

# 2. Network issue
ping 8.8.8.8  # Check internet
# Check CNI plugin

# 3. Resource exhaustion
df -h  # Disk full?
free -m  # Memory pressure?
```

**Issue 2: Pod Stuck in Pending**

```bash
# Describe Pod
kubectl describe pod webapp-abc123

# Check events:
# "0/3 nodes are available: insufficient cpu"
# â†’ Need more resources or scale cluster

# "0/3 nodes are available: node(s) had taints"
# â†’ Check node taints
kubectl describe node worker-node-1 | grep Taints
# Add tolerations to Pod if needed
```

**Issue 3: Container Keeps Crashing**

```bash
# Check Pod logs
kubectl logs webapp-abc123
kubectl logs webapp-abc123 --previous  # Previous crash

# Check container status
kubectl describe pod webapp-abc123
# Look at: LastState, Reason (OOMKilled? CrashLoopBackOff?)

# Common fixes:
# - Increase memory limits (if OOMKilled)
# - Fix application errors (check logs)
# - Adjust liveness probe (if too aggressive)
```

**Issue 4: Network Problems**

```bash
# Check Pod can reach Service
kubectl exec webapp-abc123 -- curl http://backend-service

# Check DNS
kubectl exec webapp-abc123 -- nslookup backend-service

# Check kube-proxy
kubectl get pods -n kube-system | grep kube-proxy
kubectl logs -n kube-system kube-proxy-xyz

# Check iptables rules
sudo iptables-save | grep KUBE
```

### Debugging Commands

```bash
# Node level
kubectl get nodes
kubectl describe node <node-name>
kubectl top node <node-name>

# Pod level
kubectl get pods -o wide
kubectl describe pod <pod-name>
kubectl logs <pod-name>
kubectl exec -it <pod-name> -- /bin/bash

# Container runtime
# (SSH to node first)
sudo crictl ps  # List containers
sudo crictl logs <container-id>
sudo crictl inspect <container-id>

# kubelet
sudo systemctl status kubelet
sudo journalctl -u kubelet -f

# Network
kubectl get svc
kubectl get endpoints
sudo iptables-save | grep <service-name>
```

---

## ğŸ“ Kiá»ƒm Tra Hiá»ƒu Biáº¿t

**1. kubelet lÃ m gÃ¬ khi Pod assigned to Node?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

1. Watch API Server, detect new Pod
2. Pull container image (via Container Runtime)
3. Create Pod sandbox (network namespace)
4. Create container(s) from image
5. Start container(s)
6. Run health checks (liveness, readiness)
7. Report Pod status to API Server
8. Continuously monitor vÃ  restart náº¿u cáº§n
</details>

**2. kube-proxy implement Service nhÆ° tháº¿ nÃ o?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

**iptables mode (default):**
- Táº¡o iptables rules
- DNAT Service ClusterIP â†’ Pod IPs
- Random load balancing giá»¯a Pods
- Update rules khi Pods thay Ä‘á»•i

**IPVS mode:**
- Táº¡o IPVS virtual servers
- Better performance (O(1) lookup)
- More load balancing algorithms
- Better cho large scale
</details>

**3. Container Runtime nÃ o recommended?**
<details>
<summary>Xem Ä‘Ã¡p Ã¡n</summary>

**containerd** âœ“ (recommended)
- Lightweight
- Industry standard
- Default trong nhiá»u distros
- Good performance

**CRI-O** âœ“ (alternative)
- Lightweight
- OCI-compliant
- Designed specifically for K8s

**Docker** âŒ (deprecated)
- Removed in K8s 1.24+
- Too heavy for K8s
- Use containerd instead
</details>

---

## ğŸ¯ Key Takeaways

1. **kubelet = Node Supervisor**
   - Manage Pod lifecycle
   - Report to API Server
   - Execute health checks

2. **kube-proxy = Network Manager**
   - Implement Services
   - Load balancing
   - iptables or IPVS

3. **Container Runtime = Container Engine**
   - containerd recommended
   - Pull images, run containers
   - CRI interface vá»›i kubelet

4. **Isolation via Linux Kernel**
   - Namespaces (PID, Network, Mount)
   - cgroups (CPU, Memory limits)
   - Secure container isolation

5. **Troubleshooting Workflow**
   - Check Node status
   - Check Pod describe/logs
   - Check kubelet logs
   - Check network connectivity

---

## ğŸš€ Tiáº¿p Theo

HoÃ n thÃ nh Pháº§n 2 - Architecture!

**Next:** [Pháº§n 3: Core Concepts â†’](../03-core-concepts/README.md)

á» pháº§n tiáº¿p theo, chÃºng ta sáº½ há»c cÃ¡c concepts cá»‘t lÃµi: Pod, Namespace, Labels, Selectors.

---

[â¬…ï¸ 2.2. Control Plane](./02-control-plane.md) | [ğŸ  Má»¥c Lá»¥c ChÃ­nh](../README.md) | [ğŸ“‚ Pháº§n 2: Architecture](./README.md) | [â¡ï¸ Pháº§n 3: Core Concepts](../03-core-concepts/README.md)
