# ğŸ“˜ Pháº§n 2: Architecture - Kiáº¿n TrÃºc Kubernetes

> Hiá»ƒu sÃ¢u cÃ¡ch Kubernetes hoáº¡t Ä‘á»™ng bÃªn trong

---

## ğŸ¯ Má»¥c TiÃªu Pháº§n NÃ y

Sau khi hoÃ n thÃ nh Pháº§n 2, báº¡n sáº½:

âœ… **Hiá»ƒu kiáº¿n trÃºc tá»•ng thá»ƒ** cá»§a Kubernetes Cluster  
âœ… **Náº¯m rÃµ vai trÃ²** cá»§a tá»«ng component  
âœ… **Biáº¿t cÃ¡ch components tÆ°Æ¡ng tÃ¡c** vá»›i nhau  
âœ… **Troubleshoot Ä‘Æ°á»£c** architecture-level issues  
âœ… **CÃ³ foundation vá»¯ng** Ä‘á»ƒ lÃ m viá»‡c vá»›i K8s  

---

## ğŸ“š Ná»™i Dung

### [2.1. Tá»•ng Quan Kiáº¿n TrÃºc](./01-overview.md) â­â­â­â­â­

**Thá»i gian:** 45-60 phÃºt

**Ná»™i dung:**
- Kubernetes Cluster lÃ  gÃ¬
- Big picture: Control Plane + Worker Nodes
- Kiáº¿n trÃºc tá»•ng thá»ƒ (detailed diagram)
- Control Plane vs Worker Nodes
- Communication flow overview
- Design principles (táº¡i sao kiáº¿n trÃºc nÃ y?)

**Key Concepts:**
```
âœ“ Cluster = Control Plane + Worker Nodes
âœ“ Separation of concerns (brain vs workers)
âœ“ Declarative API pattern
âœ“ Watch & reconciliation loop
âœ“ API-driven architecture
```

**BÃ i Táº­p:**
- Identify components (Control Plane hay Worker?)
- Váº½ flow: kubectl create deployment
- Trace self-healing workflow

---

### [2.2. Control Plane - Bá»™ NÃ£o](./02-control-plane.md) â­â­â­â­â­

**Thá»i gian:** 60-90 phÃºt (Cá»°C Ká»² QUAN TRá»ŒNG!)

**Ná»™i dung:**
- **API Server**: Cá»•ng vÃ o duy nháº¥t, Authentication/Authorization
- **etcd**: Database cá»§a cluster, backup strategies
- **Scheduler**: PhÃ¢n cÃ´ng Pods to Nodes (filtering + scoring)
- **Controller Manager**: Reconciliation loops, multiple controllers
- **Cloud Controller Manager**: Cloud integration

**Key Concepts:**
```
âœ“ API Server = Central hub, etcd gateway
âœ“ etcd = Single source of truth, must backup!
âœ“ Scheduler = Smart placement (resources, constraints)
âœ“ Controllers = Desired state = Actual state
âœ“ Watch pattern = Event-driven architecture
```

**Deep Dives:**
- Authentication & Authorization flow
- etcd data structure
- Scheduler scoring algorithm
- Controller reconciliation loop
- Complete deployment flow (10 steps)

**Commands:**
```bash
# Monitor Control Plane
kubectl get pods -n kube-system
kubectl logs -n kube-system kube-apiserver-<node>
kubectl get --raw /metrics

# etcd backup
etcdctl snapshot save backup.db
```

---

### [2.3. Worker Nodes - NÆ¡i Cháº¡y Apps](./03-worker-nodes.md) â­â­â­â­â­

**Thá»i gian:** 60-75 phÃºt

**Ná»™i dung:**
- **kubelet**: Node agent, Pod lifecycle management
- **kube-proxy**: Network proxy, Service implementation
- **Container Runtime**: Docker/containerd/CRI-O
- Node components interaction
- Troubleshooting Node issues

**Key Concepts:**
```
âœ“ kubelet = Node supervisor (manage Pods)
âœ“ kube-proxy = Network manager (iptables/IPVS)
âœ“ Container Runtime = Execute containers
âœ“ CRI = Container Runtime Interface
âœ“ Linux kernel features (namespaces, cgroups)
```

**Deep Dives:**
- kubelet Pod lifecycle (8 steps)
- kube-proxy iptables vs IPVS
- containerd architecture
- Container isolation mechanisms
- Complete Pod startup flow (11 steps)

**Troubleshooting:**
```bash
# Node issues
kubectl get nodes
kubectl describe node <node>
sudo systemctl status kubelet

# Network issues
kubectl get svc
kubectl get endpoints
sudo iptables-save | grep KUBE

# Container runtime
sudo crictl ps
sudo crictl logs <container-id>
```

---

## ğŸ—ºï¸ Learning Path

### Recommended Order

```
1. Start: README.md (file nÃ y)
   â†“
2. 2.1. Overview (big picture)
   â†“  
3. 2.2. Control Plane (deep dive)
   â†“
4. 2.3. Worker Nodes (execution)
   â†“
5. Next: Pháº§n 3 - Core Concepts
```

### CÃ¡ch Há»c Hiá»‡u Quáº£

**1. Visualize Architecture**
```
âœ“ Váº½ láº¡i diagrams báº±ng tay
âœ“ Annotate vá»›i notes riÃªng
âœ“ So sÃ¡nh vá»›i analogies (cÃ´ng ty, nhÃ  hÃ ng)
```

**2. Trace Flows**
```
âœ“ Follow tá»«ng bÆ°á»›c trong workflows
âœ“ Váº½ arrows giá»¯a components
âœ“ Hiá»ƒu "táº¡i sao" má»—i step
```

**3. Hands-on Later**
```
âœ“ Hiá»ƒu concepts trÆ°á»›c
âœ“ Setup cluster á»Ÿ Pháº§n 3
âœ“ Practice commands sau khi hiá»ƒu theory
```

---

## ğŸ—ï¸ Architecture Summary

### Complete Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 KUBERNETES CLUSTER                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  USER/DEVELOPER                                         â”‚
â”‚       â†“                                                 â”‚
â”‚    kubectl                                              â”‚
â”‚       â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CONTROL PLANE (Brain)                           â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  API Server â† etcd (Database)                   â”‚  â”‚
â”‚  â”‚      â†•                                           â”‚  â”‚
â”‚  â”‚  Scheduler + Controllers                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â†• (Commands & Status)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  WORKER NODES (Workers)                          â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  Node 1, 2, 3...                                â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ kubelet (Pod manager)                      â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ kube-proxy (Network)                       â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ Container Runtime                          â”‚  â”‚
â”‚  â”‚  â””â”€â”€ PODS (Applications)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Responsibilities

| Component | Location | Responsibility |
|-----------|----------|----------------|
| **API Server** | Control Plane | Cá»•ng vÃ o, authn/authz, etcd gateway |
| **etcd** | Control Plane | Database, store all state |
| **Scheduler** | Control Plane | Assign Pods to Nodes |
| **Controllers** | Control Plane | Reconcile desired vs actual state |
| **kubelet** | Worker Node | Manage Pods on Node |
| **kube-proxy** | Worker Node | Network proxy, Services |
| **Container Runtime** | Worker Node | Run containers |

---

## ğŸ“ Self-Assessment

### Checkpoint: Báº¡n ÄÃ£ Hiá»ƒu ChÆ°a?

**1. Váº½ kiáº¿n trÃºc K8s tá»« memory**
<details>
<summary>Check points</summary>

Should include:
- Control Plane: API Server, etcd, Scheduler, Controllers
- Worker Nodes: kubelet, kube-proxy, Container Runtime
- Arrows showing communication
- User/kubectl at top
</details>

**2. Giáº£i thÃ­ch flow: kubectl create deployment**
<details>
<summary>Check answer</summary>

```
1. kubectl â†’ API Server
2. API Server validates, writes to etcd
3. Deployment Controller creates ReplicaSet
4. ReplicaSet Controller creates Pods
5. Scheduler assigns Pods to Nodes
6. kubelet on Nodes pulls images, starts containers
7. Pods running!
```
</details>

**3. Component nÃ o lÃ m gÃ¬?**

Match:
1. API Server
2. etcd
3. Scheduler
4. ReplicaSet Controller
5. kubelet
6. kube-proxy

Tasks:
a. Maintain Pod replicas
b. Store cluster state
c. Run containers
d. Assign Pods to Nodes
e. Implement Services
f. Validate requests

<details>
<summary>Check answers</summary>

1. API Server â†’ f. Validate requests
2. etcd â†’ b. Store cluster state
3. Scheduler â†’ d. Assign Pods to Nodes
4. ReplicaSet Controller â†’ a. Maintain Pod replicas
5. kubelet â†’ c. Run containers
6. kube-proxy â†’ e. Implement Services
</details>

**4. Troubleshooting scenarios**

**Scenario A:** Node shows NotReady
<details>
<summary>Debug steps</summary>

```bash
1. kubectl describe node <node>
2. Check kubelet: systemctl status kubelet
3. Check logs: journalctl -u kubelet
4. Check disk/memory: df -h, free -m
5. Check network connectivity
```
</details>

**Scenario B:** Pod stuck Pending
<details>
<summary>Debug steps</summary>

```bash
1. kubectl describe pod <pod>
2. Check events: "insufficient cpu" / "no nodes available"
3. kubectl get nodes (enough resources?)
4. Check node taints/tolerations
5. Check PVC if uses storage
```
</details>

---

## ğŸ¯ Key Takeaways - Pháº§n 2

### 10 Äiá»u Quan Trá»ng Nháº¥t

**1. Cluster Architecture**
```
Cluster = Control Plane (brain) + Worker Nodes (workers)
Separation of concerns = Scalable + Maintainable
```

**2. API Server = Central Hub**
```
All communication goes through API Server
Only component talking to etcd
Authentication, Authorization, Validation
```

**3. etcd = Critical Database**
```
Stores ALL cluster state
Distributed, consistent
MUST backup regularly!
```

**4. Scheduler = Smart Placement**
```
Filter (can run?) â†’ Score (best fit?) â†’ Bind
Consider: resources, constraints, affinity
Optimize cluster utilization
```

**5. Controllers = Self-Healing**
```
Watch loop: Desired vs Actual
Automatic reconciliation
Multiple controllers for different resources
```

**6. kubelet = Pod Manager**
```
Agent on each Node
Manages Pod lifecycle
Reports status to API Server
```

**7. kube-proxy = Service Implementation**
```
Maintains network rules (iptables/IPVS)
Enables Service abstraction
Load balances to Pods
```

**8. Container Runtime**
```
containerd recommended (not Docker!)
CRI interface vá»›i kubelet
Manages container lifecycle
```

**9. Watch Pattern Everywhere**
```
Components watch API Server for changes
Event-driven architecture
React to state changes
```

**10. Declarative API**
```
Describe desired state
K8s makes it happen
Reconciliation = continuous convergence
```

---

## ğŸ“š Thuáº­t Ngá»¯ Quan Trá»ng

| Thuáº­t Ngá»¯ | Ã NghÄ©a |
|-----------|---------|
| **Control Plane** | Bá»™ nÃ£o cá»§a cluster (master components) |
| **Worker Node** | Server cháº¡y application Pods |
| **API Server** | Cá»•ng vÃ o duy nháº¥t, REST API |
| **etcd** | Distributed key-value database |
| **Scheduler** | Component phÃ¢n cÃ´ng Pods to Nodes |
| **Controller** | Component reconcile desired vs actual |
| **kubelet** | Node agent, manage Pods |
| **kube-proxy** | Network proxy, implement Services |
| **CRI** | Container Runtime Interface |
| **Reconciliation** | Process make actual = desired |

---

## â“ FAQs

**Q: CÃ³ thá»ƒ cÃ³ nhiá»u Control Plane nodes khÃ´ng?**
```
A: CÃ³! (High Availability setup)
- Multiple API Server instances (load balanced)
- Multiple Controller Manager (leader election)
- Multiple Scheduler (leader election)
- etcd cluster (3 or 5 nodes)

â†’ Survive Control Plane node failures!
```

**Q: Worker Node cÃ³ thá»ƒ lÃ  Control Plane khÃ´ng?**
```
A: Technically yes, nhÆ°ng NOT recommended production

Single-node cluster:
âœ“ Learning/development (minikube, kind)
âœ— Production

Separation Control Plane + Workers:
âœ“ Better resource allocation
âœ“ Better security
âœ“ Better scaling
```

**Q: Táº¡i sao khÃ´ng let components talk to etcd directly?**
```
A: Security vÃ  consistency!

If direct access:
âŒ No validation
âŒ No authorization  
âŒ Inconsistent updates
âŒ Hard to audit

Via API Server:
âœ“ Centralized validation
âœ“ Fine-grained RBAC
âœ“ Audit logging
âœ“ Consistent interface
```

**Q: iptables vs IPVS - nÃªn dÃ¹ng gÃ¬?**
```
A: Depends on scale

iptables (default):
âœ“ Stable, mature
âœ“ Good < 1000 services
âœ— Performance degrades vá»›i nhiá»u services

IPVS:
âœ“ Better performance (O(1))
âœ“ More load balancing algorithms
âœ“ Good for large scale (1000+ services)
âœ— Requires kernel modules
```

**Q: CÃ³ thá»ƒ thay Ä‘á»•i Scheduler logic khÃ´ng?**
```
A: CÃ³! Multiple options:

1. Custom Scheduler
   - Viáº¿t scheduler riÃªng
   - Deploy alongside default
   - Specify trong Pod: schedulerName: custom

2. Scheduler Extenders
   - Extend default scheduler
   - Add custom filter/score logic

3. Scheduler Framework
   - Plugin architecture (K8s 1.15+)
   - Write plugins for custom logic
```

---

## ğŸ”§ Setup Next Steps

**Báº¡n Ä‘Ã£ hiá»ƒu architecture!**

Next step: Hands-on vá»›i K8s

**Pháº§n 3: Core Concepts** sáº½ bao gá»“m:
```
â”œâ”€â”€ Setup local cluster (minikube/kind)
â”œâ”€â”€ First kubectl commands
â”œâ”€â”€ Create Pods, Deployments
â”œâ”€â”€ Understand Namespaces, Labels
â””â”€â”€ Hands-on practice!
```

---

## ğŸ“– Resources Bá»• Sung

### Documentation
- [Kubernetes Components](https://kubernetes.io/docs/concepts/overview/components/)
- [Cluster Architecture](https://kubernetes.io/docs/concepts/architecture/)

### Deep Dives
- [How Kubernetes Scheduler Works](https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/)
- [etcd Documentation](https://etcd.io/docs/)

### Videos
- "Kubernetes Deconstructed" - CoreOS
- "A Deep Dive Into Kubernetes Internals" - KubeCon talks

---

## ğŸš€ Tiáº¿p Theo

**Completed:** Architecture fundamentals âœ…

**Next:** [Pháº§n 3: Core Concepts â†’](../03-core-concepts/README.md)

Báº¯t Ä‘áº§u hands-on:
- Setup local cluster
- Táº¡o first Pods
- kubectl commands
- Namespaces vÃ  Labels

Let's get practical! ğŸ¯

---

[â¬…ï¸ Pháº§n 1: Introduction](../01-introduction/README.md) | [ğŸ  Má»¥c Lá»¥c ChÃ­nh](../README.md) | [â¡ï¸ Pháº§n 3: Core Concepts](../03-core-concepts/README.md)
